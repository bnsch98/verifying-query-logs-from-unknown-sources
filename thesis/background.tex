\chapter{Background}
In this chapter we review some aspects of the literature that are relevant to this work. In particular, we describe prevalent analyses of search logs that have been conducted in the past and their motivations. This includes simple syntactical analyses of the queries as well as the classification into meaningful taxonomies. We discuss whether these analyses would contribute to the objective of this work. Furthermore, as an additional background to the temporal analysis in this work, we critically point out limitations of utilizing data from Google Trends\footnote{\url{https://trends.google.com/trends/}} to investigate temporal patterns in query logs. Thereon, we elaborate on sentence embeddings and their potential usage in this work. Finally, we introduce Wasserstein distances as a method to compare distributions. 

\section{Traditional Query Log Analysis}\label{sec:traditional_query_log_analysis}
With the increasing advent of the internet during the late 1990s, search engines became an essential tool for users to navigate the web. This led to a growing interest in understanding the behavior of users when searching the web and hence an interest to study search queries. A lot of publications from this time investigate query logs to understand user behavior and the differences between information retrieval on the web and traditional information retrieval. 
\subsection*{Query Frequencies}
A common analysis among the early works is the examination of query frequencies. \citet{silverstein:1999} consider individual and repeated queries and measure their frequency. They find out that most queries are individual and conclude that the user's information need is quite diverse. In addition, they partition queries into groups that appear 1, 2, 3, or more than 3 times and measure the frequencies of these groups. \citet{spink:2001} also measure frequencies of queries with respect to the occurence in the log. They also find a small number with high frequency and a high number of unique queries. Generally, a lot of works analyze the frequency distribution of queries and discover highly skewed distributions. 
\subsection*{Terms in Queries}
Another common approach is the consideration of terms in query logs and their distribution. \citet{silverstein:1999} measure the frequency distribution of the number of terms in a query and related statistics like the mean and standard deviation of the number of terms. \citet{jansen:2000} consider mere frequency distributions of terms and create a descending-ranked distribution. They test for Zipf's Law in the ranked distribution of terms by displaying the frequency of terms in a log-log plot. \citet{spink:2001} also measure the length of queries with respect to the number of occuring terms and display this distribution. Besides testing for Zipf's Law in the term distribution, they prepare tables of the most frequent terms and their respective frequencies to provide concrete insights to the queries. \citet{jansen:2001} investigate the diversity of terms in queries and conclude that more unique terms are present in query logs than in large text corpora.  
\subsection*{Search Operators}\label{sec:search_operators}
Lastly, investigations concerning the usage of search operators in queries are covered by many works. Search operators are special characters or words that are used to refine the search. \citet{silverstein:1999} measure the fraction of queries that contain search operators and the number of search operators in a query. They find that most queries do not contain search operators. \citet{jansen:2000} also measure the frequency of search operators in queries. \citet{spink:2001} provide a list of selected search operators and their frequencies in the query logs. 

Based on this overview, we deduce the following domains to analyze query logs:
\begin{itemize}
    \item \textbf{Query Frequencies:} Generating frequency distributions of queries. From this, the creation of rankings of the queries and a subsequent test for Zipf's Law is feasible. Furthermore, a list of the most frequent queries and their frequencies might provide concrete insights.
    \item \textbf{Terms in queries:} Extracting terms and generating the distribution of terms in queries. Likewise, a test for Zipf's Law after creating a ranking is possible. In addition, we can measure a query's length in the number of its terms and generate a frequency distribution from this. For a concrete insight, we can create tables of the most frequent terms and their frequencies.
    \item \textbf{Search operators:} Creating a list of common search operators and measuring their frequencies in the query logs. 
\end{itemize}

\section{Query Classification}\label{sec:query_classification}
A common approach to refine search results is a preceding classification of the search query. Different ideas regarding what taxonomy of search queries would be useful to refine search results exist. 

\subsection*{Query Intent}\label{sec:query_intent}
One of the most prominent approaches is the idea to understand the intent behind a query and classify it accordingly. The idea of \citet{broder:2002} to focus on the intent and distinguish between navigational, informational, and transactional queries was widely adopted. According to \citet{broder:2002}, navigational queries are used to find a specific website, informational queries are used to find information about a topic, and transactional queries are used to perform a transaction, such as purchasing a product or download a file. \citet{rose:2004} and \citet{kang:2003} as well emphasize the importance of understanding the user's intent behind a query and adopt the taxonomy of \citet{broder:2002}. Those early approaches measure, among others, conditional probabilities of terms being present in a certain category and use them for classification. \citet{alexander:2022} further refine the taxonomy of \citet{broder:2002} and introduce a more fine-grained classification of informational queries. They subdivde the informational category into instrumental (i.e., how to do sth.), factual (search of facts or pieces of information) and abstain (rest of informational queries). 

\subsection*{Topic-related Categories}\label{sec:topic_related_categories}
Similar attention was given to the idea of classifying queries into topic-related categories. \citet{beitzel:2005} state that classifying queries into topic-related categories would make topic-specific databases employable. Hence, a more efficient and effective search could be performed. They attempt to classify queries into one of 18 topic-related categories and use a supervised learning approach to do so. Moreover, they develop an ensemble-classifier that involves a perceptron trained on labeled queries and a rule-based classifier which uses conditional probabilities of bigrams to classify queries. However, this method performs rather low and achieves a F1-Score of $0.12$. 

\subsection*{Challenges}\label{sec:classification_challenges}
Despite the potential benefits of classifying queries, there are several challenges associated with this task. One of the main challenges is the sparsity of information present in queries. Most queries are short and lack context, making it difficult to classify them accurately. Furthermore, query streams vary over time heavily, which even further complicates the classification task~\citep{beitzel:2005}. Due to their brevity, queries are often ambiguous and can have multiple meanings. Because of these challenges, first attempts to classify queries were not very accurate regardless the taxonomy~\citep{beitzel:2007,kang:2003,beitzel:2005}. Though, the method of \citet{alexander:2022} is more promising. They achieve an accuracy of $0.90$ when classifying queries into the three categories informational, navigational and transactional. Because of this, we focus on the intent-based taxonomy of \citet{broder:2002} and \citet{alexander:2022} in this work.  

\section{Named Entities in Queries}\label{sec:named_entities}
According to \citet{guo:2009} and \citet{zhang:2015}, over 70\% of queries contain named entities. They seem to be a substantial part of queries. \citet{zhang:2015} use query logs as a source to learn entity types and \citet{guo:2009} perform named entity recognition in queries and a subsequent classification into entity types. \citet{lin:2012} state that a lot of web search queries involve actions on entities and propose a method to automatically find queries bearing entities and suggest the most desired actions on such entities for the user. By actions the authors mean, for instance, reading reviews, watching demo videos etc. with regard to an entity that is also part of the query. Those early approaches involve manual labeling of training data and human engineering in designing domain-specific features and rules~\citep{li:2022}. Present Named Entity Recognizers (NER), however, are based on deep learning and are not dependent on designing domain-specific features by humans. Those approaches achieve state-of-the-art performance~\citep{li:2022} and are provided by open source libraries such as spaCy\footnote{\url{https://spacy.io/}}. Considering the large presence of named entities in queries and the availability of state-of-the-art NER, detecting named entities in the involved query logs seems feasible and insightful.

\section{Questions in Queries}\label{sec:questions}
Over the years, an increasing amount of queries is formulated in the form of natural language instead of a set of keywords~\citep{white:2015}. Accordingly, users also pose questions to search engines. \citet{white:2015} study the behaviour of search engines when handling questions. They filter questions from search logs by a rule-based approach and find that 2-3\% of queries are questions. \citet{bondarenko:2020} as well investigate the presence of questions in search queries. In their study, they aim at finding comparative questions and develop classifiers to do so. The work of \citet{reimer:2023a} also identifies questions in queries among other things. Here, a rule-based classifier for detecting questions in queries achieves a recall of 0.89 and an even higher precision of 0.99. Based on theses findings, a question classification of queries seems to be feasible and valuable.    
\subsubsection{Summary}
Based on the previous findings we deduce further following domains to characterize query logs:
\begin{itemize}
    \item \textbf{Query Classification:} Classifying queries into a intent-based taxonomy or a topic-related taxonomy. The resulting distributions deliver additional insights into the query log's properties. Since the classification into topic-related categories is not very accurate, we focus on the intent-based taxonomy.
    \item \textbf{Named Entity Recognition:} Identifying named entities in queries and classifying them into entity types. We obtain distributions of the entity types in the query log and can make another comparison.
    \item \textbf{Questions in queries:} Identifying questions in queries from rule-based approaches. This analysis provides another insight and additionally is simple to implement. 
\end{itemize}

\section{Temporal Patterns in Query Logs}\label{sec:temporal_patterns}
The temporal popularity of queries is another phenomenon studied in the literature. Query frequencies change over time and reflect information about general popularity of different topics and trends within society. Some queries even show periodic patterns, such as seasonal trends. \citet{shokouhi:2011} state that seasonal queries are frequent and need to be detected in order to be met appropriately by search engines. According to \citet{shokouhi:2011}, seasonal queries demand the most recent web pages and not the most clicked which is why they have to be treated differently. They propose a method that determines the seasonality of queries with high accuracy by applying time series analysis on historical frequency distributions. \citet{chien:2005} suppose that temporally correlated queries are semantically related and define a new measure of the temporal correlation of two queries. Their method successfully captures temporally correlated queries and shows that, indeed, temporal correlation is a good indicator of semantic similarity. 

\subsection*{Google Trends and its Limitations}\label{sec:google_trends}
In order to investigate temporal patterns in the AQL, we must specify a subset of queries whose temporal popularity we want to determine and compare. To make comparisons, we need realistic and reliable time series of query popularity from an external source. We choose Google Trends for this. Google Trends is a free tool that provides insights into the temporal popularity of search queries from Google. It allows us to make the necessary comparisons and subsequent conclusions on the observed temporal query popularities from the AQL. 

Despite its usefulness, the usage of Google Trends data entails some limitations that need to be taken into account. \citet{behnen:2020} conducted a study on the reliability of Google Trends data and conclude that the data is not always reliable. In their study, they review, among others, google's claim that inconsistencies are due to overall low search volume and should only appear for unpopular queries. \citet{behnen:2020} examine inconsistencies of three german queries for different time spans. They find that inconsistencies occur particularly for short time spans and queries with overall low search volume. According to this, data of google trends for english queries of large time spans should be robust. They even acknowledge that for time spans larger than eight months, the data seem to be reliable.  

In summary, we can state that comparing the popularity of different queries with data from Google Trends is feasible and valuable since we can assess temporal patterns. However, we need to be careful which queries and what time spans we choose. Considering the findings of \citet{behnen:2020}, a comparison of queries with high search volume and large time spans is reasonable.
      
% \section{Sentence Embeddings}\label{sec:sentence_embeddings}
% With the advent of the transformer architecture, a significant push of language models was initiated~\citep{zhao:2022}. The transformer architecture allows to train models on large-scale general text data, equipping such models with broad language comprehension~\citep{vaswani:2017}. As a next step, these pretrained language models are usually fine-tuned on downstream tasks, e.g., in information retrieval. That is, the language comprehension of the model is shifted to a specific task. 

% \citet{reimers:2019} further refined the architecture of such language models to pave the way for rich and efficient sentence embeddings. Rich in this case means that the embeddings encode the content of an input-text fairly well. Efficient means that the embeddings can be computed and used for further compuations with a feasible time complexity. The architecture of \citet{reimers:2019} as well is desinged for fine-tuning on downstream tasks. In information retrieval, such models are fine-tuned on the task of semantic search. Given a query, the task is to retrieve texts that are semantically similar to the query. Both, the query and the texts are encoded into embeddings and the semantic similarity can be measured via, e.g., cosine similarty of the embeddings in the latent space. 

% In this work, we employ sentence embeddings to compare the semantic similarity of queries. We use sentence embeddings of models that are fine-tuned on the task of semantic search. We expect those models to encode query semantics particularly well. However, two variations in semantic search exist: Symmetric and asymmetric semantic search. Symmetric semantic search focuses on encoding semantic similarites between texts of similar lengths. Asymmetric semantic search, though, is constrained to encode query-document similarities, i.e. similarities between texts of different lengths. In this work, we are interested in query-query similarities, i.e., similarties between textes of similar lengths. Hence, we employ symmetric semantic search embeddings. To elaborate on this, \citet{zhao:2022} state that asymmetric semantic search models are error-prone to query variations such as misspellings or small semantic changes. They mention that dense retrievers, which employ asymmetric semantic search, are known to be less robust to such variations. From this, we conclude that asymmetric semantic search models do not encode query-query similarities well enough and we focus on symmetric semantic search embeddings in this work.


\section{Wasserstein Distances} \label{sec:wasserstein_distances}
To evaluate the resulting distributions of this works's experiments, we need methods to compare the distributions of the AQL with the distributions of AOL, MS-MARCO Web Search and ORCAS, our comparison group. \textit{Wasserstein distances} quantify differences of probability distributions and are widely adopted in statistics~\citep{panaretos:2019}. Let $\mu$ and $\nu$ be two probability measures on $\mathbb{R}^d$, the $p$-Wasserstein distance is defined as   
\begin{equation}
W_p(\mu, \nu)=\inf_{\substack{X \sim \mu\\ Y \sim \nu}} \left(\mathbb{E}\|X-Y\|^p\right)^{1 / p}, \quad p \geq 1
\end{equation}
where the infimum is taken over all pairs of $d$-dimensional random vectors $X$ and $Y$ marginally distributed as $\mu$ and $\nu$~\citep{panaretos:2019}. An intuitive idea of what Wasserstein distances measure would be the minimuim effort to make two distributions coincide. They originally stem from the theory of optimal transport where one tries to find the optimal way to transport a distribution of mass to another distribution of mass~\citep{panaretos:2019}. Conveniently, Wasserstein distances satisfy all properties of a metric, i.e., non-negativity, symmetry and validity of the triangle inequality~\citep{panaretos:2019}. This makes Wasserstein distances suitable for comparisons between distributions. Wasserstein distances even generalize to probability measures defined on much more general spaces: if $(\mathcal{X}, \rho)$ is any complete metric space, then the $p$-Wasserstein distance can be defined in the same way, with $\|X-Y\|$ replaced by the metric $\rho(X,Y)$~\citep{panaretos:2019}. That is, the distance is able to inherit the metric that is already defined in the space of the considered distributions which gives a natural interpretation of Wasserstein distances.  
