\chapter{Background}
In this chapter we review some aspects of the literature that are relevant to this work. In particular, we describe prevalent analyses of search logs that have been conducted in the past and their motivations. This includes simple syntactical analyses of the queries as well as the classification into meaningful taxonomies. We discuss whether these analyses would contribute to the objective of this work. Furthermore, as an additional background to the temporal analysis in this work, we critically point out limitations of utilizing data from Google Trends\footnote{\url{https://trends.google.com/trends/}} to investigate temporal patterns in query logs. Eventually, we elaborate on sentence embeddings and their potential usage in this work. 

\section{Traditional Query Log Analysis}\label{sec:traditional_query_log_analysis}
With the increasing advent of the internet during the late 1990s, search engines became an essential tool for users to navigate the web. This led to a growing interest in understanding the behavior of users when searching the web and hence an interest to study search queries. A lot of publications from this time investigate query logs to understand user behavior and the differences between information retrieval on the web and traditional information retrieval. 
\subsection{Query Frequencies}
A common analysis among the early works is the examination of query frequencies. \citet{silverstein:1999} consider individual and repeated queries and measure their frequency. They find out that most queries are individual and conclude that the user's information need is quite diverse. In addition, they partition queries into groups that appear 1, 2, 3, or more than 3 times and measure the frequencies of these groups. \citet{spink:2001} also measure frequencies of queries with respect to the occurence in the log. They also find a small number with high frequency and a high number of unique queries. Generally, a lot of works analyze the frequency distribution of queries and discover highly skewed distributions. 
\subsection{Terms in Queries}
Another common approach is the consideration of terms in query logs and their distribution. \citet{silverstein:1999} measure the frequency distribution of the number of terms in a query and related statistics like the mean and standard deviation of the number of terms. \citet{jansen:2000} consider mere frequency distributions of terms and create a descending-ranked distribution. They test for Zipf's Law in the ranked distribution of terms by displaying the frequency of terms in a log-log plot. \cite{spink:2001} also measure the length of queries with respect to the number of occuring terms and display this distribution. Besides testing for Zipf's Law in the term distribution, they prepare tables of the most frequent terms and their respective frequencies to provide concrete insights to the queries. \citet{jansen:2001} investigate the diversity of terms in queries and conclude that more unique terms are present in query logs than in large text corpora.  
\subsection{Search Operators}\label{sec:search_operators}
Lastly, investigations concerning the usage of search operators in queries is covered by many works. Search operators are special characters or words that are used to refine the search. \citet{silverstein:1999} measure the fraction of queries that contain search operators and the number of search operators in a query. They find that most queries do not contain search operators. \citet{jansen:2000} also measure the frequency of search operators in queries. \citet{spink:2001} provide a list of selected search operators and their frequencies in the query logs. 

Based on this overview, we deduce the following domains to analyze query logs:
\begin{itemize}
    \item \textbf{Query Frequencies:} Generating frequency distributions of queries. From this, the creation of rankings of the queries and a subsequent test for Zipf's Law is feasible. Furthermore, a list of the most frequent queries and their frequencies might provide concrete insights.
    \item \textbf{Terms in queries:} Extracting terms and generating the distribution of terms in queries. Likewise, a test for Zipf's Law after creating a ranking is possible. In addition, we can measure a query's length in the number of its terms and generate a frequency distribution from this. For a concrete insight, we can create tables of the most frequent terms and their frequencies.
    \item \textbf{Search operators:} Creating a list of common search operators and measuring their frequencies in the query logs. 
\end{itemize}

\section{Query Classification}\label{sec:query_classification}
A common approach to refine search results is a preceding classification of the search query. Different ideas regarding what taxonomy of search queries would be useful to refine search results exist. 
\subsection{Query Intent}
One of the most prominent approaches is the idea to understand the intent behind a query and classify it accordingly. The idea of \citet{broder:2002} to focus on the intent and distinguish between navigational, informational, and transactional queries was widely adopted. According to \citet{broder:2002}, navigational queries are used to find a specific website, informational queries are used to find information about a topic, and transactional queries are used to perform a transaction, such as purchasing a product or download a file. \citet{rose:2004} and \citet{kang:2003} as well emphasize the importance of understanding the user's intent behind a query and adopt the taxonomy of \citet{broder:2002}. Those early approaches measure, among others, conditional probabilities of terms being present in a certain category and use them for classification. \citet{alexander:2022} further refine the taxonomy of \citet{broder:2002} and introduce a more fine-grained classification of informational queries. They subdivde the informational category into instrumental (i.e., how to do sth.), factual (search of facts or pieces of information) and abstain (rest of informational queries). 
\subsection{Topic-related Categories}
Similar attention was given to the idea of classifying queries into topic-related categories. \citet{beitzel:2005} state that classifying queries into topic-related categories would make topic-specific databases employable and hence a more efficient and effective search could be performed. They attempt to classify queries into one of 18 topic-related categories and use a supervised learning approach to do so. They develop an ensemble-classifier that involves a perceptron trained on labeled queries and a rule-based classifier which uses conditional probabilities of bigrams to classify queries. However, this method performs rather low and achieves a F1-Score of $0.12$. 

\subsection{Challenges}
Despite the potential benefits of classifying queries, there are several challenges associated with this task. One of the main challenges is the sparsity of information present in queries. Most queries are short and lack context, making it difficult to classify them accurately. Furthermore, query streams vary over time heavily, which even further complicates the classification task~\citep{beitzel:2005}. Due to their brevity, queries are often ambiguous and can have multiple meanings. Because of these challenges, first attempts to classify queries were not very accurate~\citep{beitzel:2007,kang:2003,beitzel:2005}. Though, the method of \citet{alexander:2022} is more promising. They achieve an accuracy of $0.90$ when classifying queries into the three categories informational, navigational and transactional.  

\section{Named Entities in Queries}\label{sec:named_entities}
According to \citet{guo:2009} and \citet{zhang:2015}, over 70\% of queries contain named entities. Thus, they seem to be a substatial part of queries. \citet{zhang:2015} use query logs as a source to learn entity types and \citet{guo:2009} perform named entity recognition in queries and a subsequent classification into entity types. \citet{lin:2012} state that a lot of web search queries involve actions on entities and propose a method to automatically find queries bearing entities and suggest the most desired actions on such entities for the user. By actions the authors mean, for instance, reading reviews, watching demo videos etc. with regard to an entity that is also part of the query. Those early approaches involve manual labeling of training data and human engineering in designing domain-specific features and rules~\citep{li:2022}. Present Named Entity Recognizers (NER), however, are based on deep learning and are not dependent on desingning domain-specific features by humans. Nonetheless, they achieve state-of-the-art performance~\citep{li:2022}.
\textbf{TODO: Questions}
\subsubsection{Summary}
Based on the previous findings of query classification~\ref{sec:query_classification} and named entities~\ref{sec:named_entities} we deduce further following domains to characterize query logs:
\begin{itemize}
    \item \textbf{Query Classification:} Classifying queries into a intent-based taxonomy or a topic-related taxonomy. The resulting distributions deliver additional insights into the query log's properties. Since the classification into topic-related categories is not very accurate, we focus on the intent-based taxonomy.
    \item \textbf{Named Entity Recognition:} Identifying named entities in queries and classifying them into entity types. We obtain distributions of the entity types in the query log and can make another comparison.
    \item \textbf{Questions in queries:} Identifying questions in queries from rule-based approaches. This analysis provides another insight and additionally is simple to implement. 
\end{itemize}

\section{Temporal Patterns in Query Logs}\label{sec:temporal_patterns}
The temporal popularity of queries is another phenomenon studied in the literature. Query frequencies change over time and reflect information about general popularity of different topics and trends within society. Some queries even show periodic patterns, such as seasonal trends. \citet{shokouhi:2011} state that seasonal queries are frequent and need to be detected in order to be met appropriately by search engines. According to \citet{shokouhi:2011}, seasonal queries demand the most recent information and not the most clicked which is why they have to be treated differently. They propose a method that determines the seasonality of queries with high accuracy by applying time series analysis on historical frequency distributions. \citet{chien:2005} suppose that temporally correlated queries are semantically related and define a new measure of the temporal correlation of two queries. Their method successfully captures temporally correlated queries and shows that, indeed, temporal correlation is a good indicator of semantic similarity. 

\subsection{Limitations of Google Trends} 
Google Trends is a free tool that provides insights into the popularity of search queries parsed to google over time. It allows us to compare and verify the popularity of different queries from the AQL. 

Though very helpful, the usage of Google Trends data entails some limitations that need to be taken into account. \citet{behnen:2020} conducted a study on the reliability of Google Trends data and conclude that the data is not always reliable. In their study, they review, among others, google's claim that inconsistencies are due to overall low search volume and should only appear for unpopular queries. \citet{behnen:2020} examine inconsistencies of three german queries for different time spans. They find that inconsistencies occur particularly for short time spans and queries with overall low search volume. According to this, data of google trends for english queries of large time spans should be robust. They even acknowledge that for time spans larger than eight months, the data seem to be reliable.  

In summary, we can state that comparing the popularity of different queries with data from Google Trends is feasible and valuable since we can assess temporal patterns. However, we need to be careful which queries we choose and what time spans we want to consider. Following the findings of \citet{behnen:2020}, a comparison of queries with high search volume and large time spans is reasonable.
      
\section{Sentence Embeddings}\label{sec:sentence_embeddings}
With the advent of the Transformer architecture, a significant push of language models was initiated~\citep{zhao:2022}. The transformer architecture allows to train models on large-scale general text data and thus create models with broad language comprehension. These pretrained language models can be used for fine-tuning on downstream tasks, e.g., in information retrieval. 

\citet{reimers:2019} further refined the architecture of such language models to pave the way for rich and efficient sentence embeddings which can be used for large-scale semantic search. Semantic search is the task of retrieving text documents that are semantically similar to a given query. 

The field of semantic search can be divided into symmetric and asymmetric semantic search. Asymmetric semantic search focuses on the problem of retrieving similar documents to a query. In this case, employed models are fine-tuned on encoding query-document similarities. Its application is constrained to finding similarities between short, keyword-like texts and document-like texts. Symmetric semantic search in contrast, focuses on finding similarites between texts of similar lengths. In this case, the employed models are fine-tuned in a more general way and not solely on query-document similarities. That is why we apply symmetric semantic search embeddings in this work. To elaborate on this, \citet{zhao:2022} state that asymmetric semantic search models are error-prone to query variations such as misspellings or small semantic changes. They mention that dense retrievers, which employ asymmetric semantic search, are known to be less robust to such variations. From this, we conclude that asymmetric semantic search models do not encode query-query similarities well enough. 

