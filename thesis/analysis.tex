
\chapter{Experiments}  
This chapter covers the analyses that we carry out on the involved query logs and related information regarding the used computational framework and general setup. For each analysis, we again provide a brief motivation and, if necessary, add information to complete the theoretical background. Furthermore, we describe in detail how the analysis is conducted. Eventually, we evaluate each analysis and discuss the obtained results.  

\section{Computational Framework}
Since we are processing large data sets (recall that the AQL contains around 356 million queries), it is favorable to employ a distributed computing framework which allows for parallel processing and distributed memory management. Moreover, many pretrained models and ML-related libraries are available in python. Therefore, we choose \textit{Ray}\footnote{\url{https://docs.ray.io/en/latest/index.html}}, an open-source distributed computing framework for python applications, as our environment for implementing and executing the analyses. Ray provides a high-level API that enables parallelizing python code without much effort. The Ray API includes methods whose call starts parallel processing of a parsed function. By this, we can easily parallelize our implemented functions that perform desired transformations on the data. In addition, Ray provides API-calls for parallel reading and writing of data on the distributed system, thus providing a fully parallel pipeline. 

\subsection{Ray API-Calls}
There are different paradigms to transform data in Ray. In this work, we mainly make use of the API-calls~\verb|map_batches()|,~\verb|flat_map()| and~\verb|groupby()|. 
\begin{itemize}
    \item \verb|map_batches()|: This API-call is used to make transformations on each row of the respective data set. That is, for each row we get one result. It takes a user-defined function as an argument and applies it to each row of the data set. The data set is transformed in batches, i.e., on each batch map_batches() is invoked. In addition, we can specifiy the configuration of execution, e.g., the number of parallel workers, the amount of required memory for each worker and the number of CPUs or GPUs for each worker.   
    \item \verb|flat_map()|: This API-call is mainly used to extract specified elements of the data. It is detached from the constraint of returning one result per row of map_batches and can handle multiple results from each row. It is applied to each row of the data set and returns a new data set with the extracted elements. The resulting data set can be of different size than the original one. As in map_batches(), we can specify the configuration of execution. 
    \item \verb|groupby()|: This API-call is used to group the data set by a specified column. It returns a new data set with the grouped elements. In addition, we can apply further functions to each group, e.g., we can apply a function to count the number of elements in each group. This API-call does not support specifiying the configuration of execution.    
\end{itemize}       

\section{Structure-related Statistics}
In this section, we generate a set of structure-related statistics from the query logs. The analyses in this section are based on the findings of Section~\ref{sec:traditional_query_log_analysis}. Additionally, aspects of the analysis of named entities (see Section~\ref{sec:named_entities}) are included in this section, too.

The goal is to perform a comparison of the query logs' linguistic and structural composition, initially neglecting semantical information of the queries.  
We collect a set of distributions from the cleaned AQL and the other involved query logs. Ultimately, we evaluate similarities of the distributions by conducting hypothesis tests or computing distances. By this, we identify syntactical differences between the AQL and the other query logs. 

For this analysis, we look at queries from different syntactic perspectives and carry out measurements in the defined perspectives. We define the following categories as syntactic perspectives:
\begin{enumerate}
    \item \textbf{Queries}
    \item \textbf{Named Entities}
    \item \textbf{Words}
    \item \textbf{Characters}
\end{enumerate} 
Even though named entities are not considered a syntactic category primarily, we include them in this analysis since they are frequent enough to be regarded a structural element of queries. Also, their analysis might provide an additional valuable insight to the structure of query logs. To add on that, we recall from Section~\ref{sec:named_entities} that up to 70\% of queries contain named entities. 

For each of the aforementioned categories (queries, named entities, words and characters), we carry out two types of measurements: 
\begin{enumerate}
    \item \textbf{Frequencies of Linguistic Elements:} We extract all elements of a category from the query log and determine the frequency of each element. For instance, we extract all existing words from the query log and measure each word's frequency. Accordingly, we proceed for all categories.
    \item \textbf{Length-Related Frequencies:} We measure the lengths of all extracted items from a category in terms of all possible subcategories. The defined syntactic categories are subject to a hierachical order, i.e., queries can be described as a set of named entities, words or characters. Words, in turn, can not be described as a set of named entities. Accordingly, we measure lengths of queries in terms of named entities, words and characters. Named entities are measured by the count of words or characters. By continuing this procedure for all categories, we gain a thorough set of measurements for each query log.
\end{enumerate}

\subsection{Frequencies of Linguistic Elements}
To obtain the frequency of liguistic elements, we first extract all elements of a category from the query log and measure each element's frequency. In the following, we present the extraction of words and the subsequent frequency measurement as an example to illustrate how we proceed for all categories. Besides reading and writing the data, this experiment consists of two major steps in the Ray environment:
\begin{enumerate}
    \item \textbf{Extraction of Words:} We apply the~\verb|flat_map()| API-call to extract all words from the query log. We parse a tokenizer function to the API-call that splits each query into its words. The tokenizer function is applied to each query of the data set and returns a set of words which are appended to the result set.  
    \item \textbf{Frequency Measurement:} We apply the~\verb|groupby()| API-call to group the data set by the extracted words. By this, we obtain a group for each extracted word. Thereon, we call a~\verb|count()| in order to count each word's occurence in the query log. In the end, we obtain a data set with the words and their frequencies.
\end{enumerate}
In the following table, we note some key parameters of the experiments on the cluster to enhance reproducibility. 


\subsubsection{Evaluation of Linguistic Elements}
For each query log, we extract all elements of a category and determine the frequency of each element. For instance, we extract all exisiting words from the query log and measure each word's frequency. The frequency distribution of linguistic elements typically obey Zipf's law when ordered in a descending order. Especially the frequency distribution of words is well studied and a popular example of Zipf's law~\citep{piantadosi:2014}. Zipf's law states that the frequency $f$ of an element is inversely proportional to its rank $r$ in the frequency table with some scaling constant $c$ and exponent $\alpha \approx 1$:
\begin{equation}
    f \propto \frac{c}{r^{\alpha}}
\end{equation} 
We test the frequencies of queries, named entities, words and characters for Zipf's law by sorting them in descending order and displaying them in a log-scaled graph. Albeit primarily studied for words, we attempt to retrieve Zipf's law also in the frequencies of queries, named entities and characters since they as well are linguistic categories and probably follow linguistic dynamics. Figure~\ref{fig:zipf-named-entities-words} shows the ordered frequencies of named entities and words in the query logs. Note that this and all subsequent plots contain data from the cleaned AQL. As for named entities, we can state that all distributions follow Zipf's law reasonably well. The distributions show a relatively constant slope in the log-scaled dimensions and are generally very similar. For the most part, this is also true for the word frequencies, despite a small deviation. The constant slope is interrupted by a small curvature in the central part of the distribution. This interruption is however not striking and is present in all distributions.  
\begin{comment}
    Verweis auf hypothesen test
\end{comment} 

\begin{figure}
    \centering
    \import{../plots/updated_plots/extract-named-entities-and-extract-words-single}{all.pgf}
    \caption{The relative frequencies of extracted named entities and words are displayed in a log-scaled graph for each query log. The frequencies were ordered in a descending order to create a ranking. Hence the depiction of frequencies and the rank. A good fit to Zipf's law is indicated by a straight line in the log-scaled dimensions.}
    \label{fig:zipf-named-entities-words}
\end{figure} In Figure~\ref{fig:zipf-queries-chars}, the frequencies of queries and characters in the query logs are displayed. The query distributions show a good fit to Zipf's law. The distributions are very similar and a constant slope in the log-scaled dimensions is present. The distributions of characters in contrast do not fit Zipf's law. Generally, the distributions of the involved data sets are quite different. It is striking that the AOL and the ORCAS log contain less characters than the AQL and the MS-MARCO log. This is probably due to their monolingual composition. Contrarily, AQL and MS-MARCO are multilingual, hence contain more characters. Moreover, all query logs commonly show that there is a group of very frequent and rather uniformly distributed characters while the frequencies of less frequent characters are decreasing even more rapidly than Zipf's law would suggest. This might be the case because alphanumeric characters are significantly more frequent than special characters which would skew the distribution. 
\begin{comment}
    Verweis auf hypothesen test
\end{comment}      
\begin{figure}
    \centering
    \import{../plots/updated_plots/query-frequencies-and-extract-chars-single}{all.pgf}
    \caption{The relative frequencies of queries and extracted characters are displayed in a log-scaled graph for each query log. The frequencies were ordered in a descending order to create a ranking. Hence the depiction of frequencies and the rank. A good fit to Zipf's law is indicated by a straight line in the log-scaled dimensions.}
    \label{fig:zipf-queries-chars}
\end{figure}

\subsubsection{Comparison of the Distributions}
TO DO: Problem: Arrays too large for scipy's wasserstein function
\subsection{Length-Related Frequencies}
Besides considering the frequency of linguistic elements, we also measure the lengths of the elements in terms of different subcategories. We describe the length of an element by the occuring counts of a possible subcategory, e.g., the length of a query by the count of characters the query contains. In Figure~\ref{fig:lengths-query-characters-named-entity-characters}, the distributions of query and named entity lengths measured in characters are displayed. As for queries, the distributions appear to be not very close but still similar to each other. The range of query lengths is quite similar among all logs. Regarding the shape, AOL and AQL are similar, though the AQL's distribution is more noisy. ORCAS stands out presenting a binomial-like distribution. MS-MARCO's distribution is also unique but unlike ORCAS not symmetrical. Regarding the distributions of named entities, we can again observe a common scope of lengths among all logs and similar shapes. Especially ORCAS and AOL are very similar to one another. The AQL's distribution is similar to a poisson distribution whereas MS-MARCO's distribution is not exactly assignable to a popular distribution.\begin{comment}
    Verweis auf wasserstein distanzen
    #### stand 04.03.2025
\end{comment}In Figure~\ref{fig:lengths-words-characters-queries-named-entities} the distributions of word and query lengths measured in characters and named entities are displayed. We can observe very similar frequencies of entity counts in queries. The distributions are almost equivalent among the involved query logs. As for the word lengths, the distributions are also similar but depict some clear differences, as well. While MS-MARCO and ORCAS show a very similar distribution, AOL's distribution is clearly different. We can observe an unusual peak of word lengths between 10 and 20 characters. Reviewing AOL's words of this lengths showed that the most frequent words are website addresses in this range. The extensions before and after the website's name (i.e. "www" or ".com") cause a shift of frequent words towards longer words. This has been confirmed by filtering out website addresses from the AOL and subsequently measure the word legth distribution. 
\begin{comment}
    In Figure~\ref{fig:lengths-words-characters-aol-cleaned} the distribution without website addresses is displayed. It is very similar to the other query logs' distributions of word lengths.    
\end{comment}
\begin{comment}
    Verweis auf wasserstein distanzen
    #### stand 05.03.2025
\end{comment} 
In Figure~\ref{fig:lengths-query-words-named-entity-words} the distributions of query and named entity lengths measured in the number of words are displayed. Concerning the lengths of named entities, we can observe almost equivalent distributions of AOL and MS-MARCO. The distribution of ORCAS is still similar to AOL and MS-MARCO while the distribution of the AQL is slightly different. The AQL contains significantly more named entities comprised of one word than the other logs. In contrast to the other logs, named entities comprised of one word a the most common named entities. A similarity among all logs is that named entities consisting of two words are the most frequent. As of the query lengths measured in words, we can observe more diverse distributions among the different logs. While the number of words is distributed similarily in AOL and AQL, the distributions of ORCAS and MS-MARCO are different. The distribution of ORCAS resembles a poisson distribution and the distribution of MS-MARCO is not clearly assignable to a popular distribution. However, the range of the most frequent number of words is similar among all logs.
\begin{comment}
    Verweis auf wasserstein distanzen
    #### stand 05.03.2025
\end{comment}
\subsubsection{Comparison of the Distributions}

The resulting distributions of the measurements are then compared to each other. We apply the \textit{Wasserstein Distance} to evaluate similarities between the resulting distributions. The Wasserstein distance is a distance measure between two probability distributions. Since we are rather interested in comparisons between distances than absolute values, the Wasserstein distance is a suitable choice because it fulfils the axioms to be considered a metric~\citep{panaretos:2019}. Hence, we can deduce conclusions from comparing the obtained numbers of the Wasserstein distances and thereby evaluate the similarities of the distributions. 


In order to quantify similarities of the aforementioned distributions, we compute the Wasserstein distance between the distributions of the query logs for each analysis. Concerning one specific anaylsis, for each query log we obtain a set of distances that represent the similaries to the other query log's distributions. In Table~\ref{tab:wasserstein-distances} the average Wasserstein distances of each query log are displayed with regard to the conducted analysis. Even though the AQL shows the highest distances to the other query logs in most analyses, the distances are not significantly different. Hence, we can deduct that the AQL fits the other logs in structural or linguisitc terms. In Figure~\ref{fig:wasserstein-distances-lengths} a configuration of the distributions is displayed that visualizes the Wasserstein distances. The configuration was derived from the Wasserstein distances by applying multidimensional scaling to the resulting distance matrix. As the numbers already indicated, clear differences of the distances are not visible. The points are distributed quite evenly and no clear clusters are visible.   
\begin{figure}[h]
    \centering
    \import{../plots/updated_plots/character-count-frequencies-queries-and-character-count-frequencies-named-entities}{all.pgf}
    \caption{The relative frequencies of query and named entity lengths measured in the number of characters are displayed.}
    \label{fig:lengths-query-characters-named-entity-characters}
\end{figure} 
    
\begin{figure}
    \centering
    \import{../plots/updated_plots/character-count-frequencies-words-and-entity-count-frequencies-queries}{all.pgf}
    \caption{The relative frequencies of word and query lengths are displayed. In this collection, the word length is measured in number of characteres. The query length is measured in the number of occuring named entities.}
    \label{fig:lengths-words-characters-queries-named-entities}
\end{figure} 

\begin{figure}
    \centering
    \import{../plots/updated_plots/word-count-frequencies-queries-and-word-count-frequencies-named-entities}{all.pgf}
    \caption{The relative frequencies of query and named entity lengths are displayed. Both, the query length and the named entity length are measured in number of occuring words.}
    \label{fig:lengths-query-words-named-entity-words}
\end{figure} 


\begin{table}
    \centering
    \begin{tabular}{@{}lrrrr@{}} \toprule
        % &  & Query Length Characters &  &  \\ \midrule
        \multicolumn{5}{c}{Query Length Characters} \\ \midrule
        & AOL & AQL & MS-MARCO & ORCAS \\ 
        AOL & 0.00 & 5.54 & 2.56 & 3.72 \\
        AQL & 5.54 & 0.00 & 4.75 & 7.75  \\
        MS-MARCO & 2.56 & 4.75 & 0.00 & 3.00 \\
        ORCAS & 3.72 & 7.75 & 3.00 & 0.00 \\ \midrule
        \multicolumn{5}{c}{Entity Length Characters} \\ \midrule
        & AOL & AQL & MS-MARCO & ORCAS \\ 
        AOL & 0.00 & 2.12 & 1.79 & 0.80 \\
        AQL & 2.12 & 0.00 & 2.86 & 1.98  \\
        MS-MARCO & 1.79 & 2.86 & 0.00 & 1.03 \\
        ORCAS & 0.80 & 1.98 & 1.03 & 0.00 \\ \midrule
        \multicolumn{5}{c}{Word Length Characters} \\ \midrule
        & AOL & AQL & MS-MARCO & ORCAS \\ 
        AOL & 0.00 & 3.69 & 6.31 & 4.20 \\
        AQL & 3.69 & 0.00 & 6.29 & 4.17  \\
        MS-MARCO & 6.31 & 6.29 & 0.00 & 2.20 \\
        ORCAS & 4.20 & 4.17 & 2.20 & 0.00 \\ \midrule
        \multicolumn{5}{c}{Query Length Words} \\ \midrule
        & AOL & AQL & MS-MARCO & ORCAS \\ 
        AOL & 0.00 & 0.58 & 0.69 & 0.89 \\
        AQL & 0.58 & 0.00 & 0.81 & 1.25  \\
        MS-MARCO & 0.69 & 0.81 & 0.00 & 0.44 \\
        ORCAS & 0.89 & 1.25 & 0.44 & 0.00 \\ \midrule
        \multicolumn{5}{c}{Entity Length Words} \\ \midrule
        & AOL & AQL & MS-MARCO & ORCAS \\ 
        AOL & 0.00 & 0.19 & 0.06 & 0.11 \\
        AQL & 0.19 & 0.00 & 0.18 & 0.30  \\
        MS-MARCO & 0.06 & 0.18 & 0.00 & 0.17 \\
        ORCAS & 0.11 & 0.30 & 0.17 & 0.00 \\ \midrule
        \multicolumn{5}{c}{Query Length Entities} \\ \midrule
        & AOL & AQL & MS-MARCO & ORCAS \\ 
        AOL & 0.00 & 0.18 & 0.12 & 0.03 \\
        AQL & 0.18 & 0.00 & 0.06 & 0.15  \\
        MS-MARCO & 0.12 & 0.06 & 0.00 & 0.09 \\
        ORCAS & 0.03 & 0.15 & 0.09 & 0.00 \\ 
        \bottomrule
    \end{tabular}
    \caption{Average Wasserstein distances between the distributions of the query logs. For each analysis, e.g. queries in characters, the Wasserstein distance between the distributions of the query logs is computed. The table contains the mean of each query log's Wasserstein distances to the other query logs for each analysis.}
    \label{tab:wasserstein-distances}        
\end{table}



\begin{comment}
    vielleicht noch die Zellen mit den jeweils größten Distanzen markieren
\end{comment}
% \begin{figure}
%     \centering
%     \import{../plots/character-count-frequencies-words}{aol-domains-cleaned.pgf}
%     \caption{Lorem ipsum dolor sit amet, consectetuer adipisc-
%     ing elit. Etiam lobortis facilisis sem.}
%     \label{fig:lengths-words-characters-aol-cleaned}
% \end{figure} 


% \begin{figure}
%     \centering
%     \import{../plots/updated_plots/query-frequencies-and-extract-chars-single}{all.pgf}
%     \caption{Zipf's law with cleaned aql}
%     \label{fig:cleaned-zipf-queries-chars}
% \end{figure} 

% \begin{figure}
%     \centering
%     \import{../plots/updated_plots/character-count-frequencies-queries-and-character-count-frequencies-named-entities}{all.pgf}
%     \caption{Zipf's law with cleaned aql}
%     \label{fig:cleaned-lengths-query-characters-named-entity-characters}
% \end{figure} 

% \begin{figure}
%     \centering
%     \import{../plots/updated_plots/characer-count-frequencies-words-and-entity-count-frequencies-queries}{all.pgf}
%     \caption{Zipf's law with cleaned aql}
%     \label{fig:cleaned-lengths-word-characters-query-named-entity}
% \end{figure} 

% \begin{figure}
%     \centering
%     \import{../plots/updated_plots/word-count-frequencies-queries-and-word-count-frequencies-named-entities}{all.pgf}
%     \caption{Zipf's law with cleaned aql}
%     \label{fig:cleaned-lengths-query-words-named-entity-words}
% \end{figure} 


\begin{figure}
    \centering
    \import{../plots/Wasserstein-Distances-Lengths}{all.pgf}
    \caption{Visualization of Wasserstein distances. The distances were computed between the distributions of the query logs for each analysis regarding length-related frequencies. The configuration of the visible points was obtained by applying multidimensional scaling to the Wasserstein distance matrix.}
    \label{fig:wasserstein-distances-lengths}
\end{figure}


% \section{Distribution-based}
% In this section, distributions of labels are created from different NLP predictors. The general idea is to compare the different data sets according to their resulting distributions of different domains.  
% \begin{itemize}
%     \item Plausibilitätsstudie für die classifier: 50-100 samples pro label pro classifier: manuell annotieren und dann accuracy bestimmen.
%     \item Intent
%     \begin{itemize}
%         \item Navigational, transactional and informational
%         \begin{itemize}
%             \item mapping (apply ORCAS-I classifier)
%         \end{itemize}
%     \end{itemize}
%     \item Named Entities
%     \begin{itemize}
%         \item Frequency of named entities \begin{itemize}
%             \item flat mapping->group->reduction
%         \end{itemize} 
%         \item Most common named entities
%         \item Categorize named entities according to ... -> apply classifier?
%     \end{itemize}
%     \item Hate speech
%     \begin{itemize}
%         \item mapping (apply hate speech classifier)
%     \end{itemize}
%     \item NSFW
%     \begin{itemize}
%         \item mapping (apply NSFW classifier)
%     \end{itemize}
%     \item Spam
%     \begin{itemize}
%         \item mapping (apply spam classifier)
%     \end{itemize}
%     \item Content
%     \begin{itemize}
        
%         \item Classify into topic taxonomy 
%         \begin{itemize}
%             \item mapping apply topic classifier
%         \end{itemize}
%     \end{itemize}
    
% \end{itemize}
% \section{Temporal-based}
% \begin{itemize}
%     \item Discover Google Trends in Data
%     \item Plot frequency of selected topics over time per data set
%     \item Seasonal topics

    
% \end{itemize}
% \section{Embedding-based}
% \begin{itemize}
%     \item Extract document vectors from e.g. BERT
%     \begin{itemize}
%         \item Create t-SNE plot with regard to intent, topics,... further categories
%         \item Apply clusterting algorithm and compare resulting clustersX 
%     \end{itemize}
%     \item Topic Modeling
%         \begin{itemize}
%             \item Compare most common topics
%             \item Compare variety of topics
%         \end{itemize}
% \end{itemize}


