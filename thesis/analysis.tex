
\chapter{Experiments}  
This chapter covers the analyses that we carry out on the involved query logs and related information regarding the used computational framework and general setup. For each analysis, we again provide a brief motivation and, if necessary, add information to complete the theoretical background. Furthermore, we describe in detail how the analysis is conducted. Eventually, we evaluate each analysis and discuss the obtained results. In this section, we provide detailed descriptions on how we carry out the analyses. Though, in order to precisely reprodcue the obtained results, we refer to this GitLab-Repository~\footnote{\url{https://git.webis.de/code-teaching/theses/thesis-schneg}}. The repository contains the source code to run the analyses and instructions on how to set up the environment.

\section{Computational Framework}
Since we are processing large data sets (recall that the AQL contains around 356 million queries), it is favorable to employ a distributed computing framework which allows for parallel processing and distributed memory management. Moreover, many pretrained models and ML-related libraries are available in python. Therefore, we choose \textit{Ray}\footnote{\url{https://docs.ray.io/en/latest/index.html}}, an open-source distributed computing framework for python applications, as our environment for implementing and executing the analyses. Ray provides a high-level API that enables parallelizing python code without much effort. The Ray API includes methods whose call starts parallel processing of a parsed function. By this, we can easily parallelize our implemented functions that perform desired transformations on the data. In addition, Ray provides API-calls for parallel reading and writing of data on the distributed system, thus providing a fully parallel pipeline. 

\subsection{Ray API-Calls}
There are different paradigms to transform data in Ray. In this work, we mainly make use of Ray's following API-calls: 
\begin{itemize}
    \item \verb|map_batches()|: This API-call is used to perform transformations on the data set. In this case, transformations are carried out on batches of the data set, enabling vectorized transformations from, e.g., numpy operations. Map_batches() takes a user-defined function or a callable class as an argument and applies it to each batch of the data set. The execution is configurable: We can specifiy the the number of parallel workers, the amount of required memory for each worker or the number of CPUs or GPUs for each worker. Map_batches() is Ray's preferable API-call for performing offline batch inference.  
    \item \verb|flat_map()|: This API-call is mainly used to extract specific elements of the data. It is detached from the constraint of returning at most one result per row and can handle multiple results from each row. The flat_map()-call is applied to each row of the data set and returns a new data set with the extracted elements. The resulting data set can be of different size than the original one. As in map\_batches(), we can specify the configuration of execution. 
    \item \verb|groupby()|: This API-call is used to group the data set by a specified key. It returns a new data set with the grouped elements. In addition, we can apply further functions to each group, e.g., we can apply a function to count the number of elements in each group. This API-call does not support specifiying the configuration of execution.    
\end{itemize}       

\section{Structure-related Statistics}
In this section, we generate a set of structure-related statistics from the query logs. The analyses in this section are based on the findings of Section~\ref{sec:traditional_query_log_analysis}. Additionally, aspects of the analysis of \hyperref[sec:named_entities]{named entities} are included in this section, too. The goal is to perform a comparison of the query logs' linguistic and structural composition, initially neglecting semantic characteristics. We collect a set of distributions from the \hyperref[sec:aql-cleaning]{cleaned AQL} and the other involved query logs. Ultimately, we evaluate similarities of the distributions by computing distances between them. This allows for identifying syntactical differences or similarities.

For this analysis, we look at queries from different syntactic perspectives and carry out measurements in the defined perspectives. We define the following categories as syntactic perspectives:
\begin{enumerate}
    \item \textbf{Queries}
    \item \textbf{Named Entities}
    \item \textbf{Words}
    \item \textbf{Characters}
\end{enumerate} 
Even though named entities are not considered a syntactic category primarily, we include them in this analysis since they are frequent enough to be regarded a structural element of queries. Also, their analysis might provide an additional valuable insight to the structure of query logs. To add on that, we recall from Section~\ref{sec:named_entities} that up to 70\% of queries contain named entities. 

For each of the aforementioned categories (queries, named entities, words and characters), we carry out two types of measurements: 
\begin{enumerate}
    \item \textbf{Frequencies of Linguistic Elements:} We extract all elements of a category from the query log and determine the frequency of each element. For instance, we extract all existing words from the query log and measure each word's frequency. We proceed accordingly for all categories.
    \item \textbf{Length-related Frequencies:} We measure the lengths of all extracted items from a category in terms of all possible subcategories. The defined syntactic categories are subject to a hierachical order, e.g., queries can be described as a set of named entities, words or characters. Words, in turn, can not be described as a set of named entities. Accordingly, we measure lengths of queries in terms of named entities, words and characters. Named entities are measured by the count of words or characters. By continuing this procedure for all categories, we gain a thorough set of measurements for each query log.
\end{enumerate}

\subsection{Frequencies of Linguistic Elements}
To obtain the frequency of liguistic elements, we first extract all elements of a category from the query log and subsequently measure each element's frequency. Besides reading and writing the data, this experiment consists of two major steps in the Ray environment:
\begin{enumerate}
    \item \textbf{Extraction of Linguistic Elements:} We apply the~\verb|flat_map()| API-call to extract all elements of a linguistic category from the query log. For named entities and words, we parse a spaCy-model to the API-call that performs named entity recognition or tokenization into words. The model is applied to each query of the data set and returns the found elements which are appended to the result set. In the end, we obtain a data set that contains all extracted elements of a liguistic category.  
    \item \textbf{Frequency Measurement:} We apply the~\verb|groupby()| API-call to group the data set by the extracted linguistic elements. Thereon, we call a~\verb|count()| to count the items of each group, which provides us with each elements's frequency in the query log. Eventually, we obtain a data set with the linguistic elements and their frequencies.
\end{enumerate}
In Table~\ref{tab:experiment-parameters-ling-elements}, we note some key parameters of the experiments to enhance reproducibility. We only list the parameters' extreme values, such as the maximum number of used workers, to indicate the maximum of required ressources.

\begin{table}[tb]
    \centering
    \begin{tabular}{@{}lr@{}} \toprule
        \textbf{Max. Number of Workers} & 32 \\    
        \textbf{Max. Number of CPUs per Worker} & 1 \\ 
        \textbf{Max. Memory per Worker} & 12 GB \\ 
        \textbf{Max. Duration} & 24h \\
        \textbf{Used Models} & \textit{spaCy-Tokenizer}, \textit{spaCy-NER} \\
        \bottomrule
    \end{tabular}
    \caption{The parameter values of this table are the extreme values of the configuration to run the extractions of linguistic elements. Both models, the spaCy-Tokenizer and the spaCy-NER are part of spaCy's \texttt{en\_core\_web\_sm}-model, which was used for this analysis.\protect\footnotemark}
    \label{tab:experiment-parameters-ling-elements}
\end{table}
\footnotetext{{\scriptsize\url{https://github.com/explosion/spacy-models/releases/tag/en_core_web_sm-3.7.1}}}

\subsubsection{Evaluation of Linguistic Elements}
As stated in Section~\ref{sec:traditional_query_log_analysis}, a well-studied phenomenon is the frequency distribution of terms in query logs. Several studies conclude that ranked frequency distributions of terms in query logs resemble Zipf's law. Zipf's law originates from linguistics and is meaningful, among other things, to describe frequency distributions of words in natural language texts~\citep{piantadosi:2014}. The law states that the frequency $f$ of an element is inversely proportional to its rank $r$ in the frequency table with some scaling constant $c$ and exponent $\alpha \approx 1$:
\begin{equation}
    f \propto \frac{c}{r^{\alpha}}
\end{equation} 
We investigate the frequencies of all considered categories, namely queries, named entities, words and characters, and evaluate two things: the similarities of the resulting distributions and if they resemble Zipf's law. To achieve this, we take two approaches: Firstly, we visualize the results in log-log-scaled graphs to assess the proximity to Zipf's law. A constant slope would suggest a Zipfian distribution. Albeit primarily studied for words, we attempt to retrieve Zipf's law also in the frequencies of queries, named entities and characters since they as well are linguistic categories and probably follow linguistic dynamics. Secondly, we numerically compare the distributions by measuring distances between them. In this case, we are primarily interested in the differences of two groups: the pairwise distances of the AQL to each of the other query logs and the pairwise distances within the comparison group, namely AOL, MS-MARCO Web Search and ORCAS. 

For evaluation we consider the frequencies of the linguistic elements sorted in descending order, i.e., rank-size distributions. Accordingly, we initially only evaluate the relationship of rank and frequency.  

\subsubsection{Rank-size Distributions of Named Entities and Words}
To assess similarities to Zipf's law, we display the frequencies sorted in descending order in a log-log-scaled graph. Figure~\ref{fig:zipf-named-entities-words} shows the ordered frequencies of named entities and words in the query logs. As for named entities, we can state that all distributions fairly resemble Zipf's law. The distributions show a relatively constant slope in the log-scaled dimensions. The slope of the word frequencies, in turn, is not as constant. We can observe a small deviation: The constant slope is interrupted by a small curvature in the central part of the distribution. However, this curvature is present in all distributions. Consequently, from a visual perspective, we can conclude that the distributions of the different data sets are quite similar. No striking outliers which indicate clear differences are visible. Though, the rank-size distribution of named entities is more similar to a Zipfian distribution than the distribution of words. 

 
\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\textwidth]{../plots/updated_plots/extract-named-entities-and-extract-words-single/all.pdf} 
  \caption{The relative frequencies of extracted named entities and words are displayed in a log-scaled graph for each query log. The frequencies were ordered in a descending order to create a ranking. A straight line in the log-scaled dimensions indicates similarities to Zipf's law.}
  \label{fig:zipf-named-entities-words}
 \end{figure}


\subsubsection{Rank-size Distributions of Queries and Characters}
In Figure~\ref{fig:zipf-queries-chars}, the frequencies of queries and characters are displayed in the log-scaled graph. The query distributions as well comply reasonably well with Zipf's law. The distributions are similar and a constant slope is present in the log-scaled dimensions. In turn, the distributions of characters do not resemble Zipf's law. They are actually quite different among the query logs. Though, it is striking that AOL and ORCAS are similar as well as MS-MARCO Web Search and AQL. 
This is probably due to their language distribution. AQL and MS-MARCO Web Search are multilingual query logs, whereas AOL and ORCAS are English-only query logs. Hence, the character distributions of the English-only query logs are similar and the distributions of the multilingual query logs are also similar. Additionally we can observe a significant difference in the number of characters. The multilingual query logs contain much more characters then the English-only logs which seems logical. Moreover, all query logs commonly show that there is a group of very frequent and rather uniformly distributed characters while the frequencies of less frequent characters are decreasing even more rapidly than Zipf's law would suggest. This might be the case because alphanumeric characters are probably significantly more frequent than special characters, indicating why the distribution is even more skewed.
     
\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\textwidth]{../plots/updated_plots/query-frequencies-and-extract-chars-single/all.pdf} 
  \caption{The relative frequencies of queries and extracted characters are displayed in a log-scaled graph for each query log. The frequencies were ordered in a descending order to create a ranking. A straight line in the log-scaled dimensions indicates similarities to Zipf's law.}
  \label{fig:zipf-queries-chars}
\end{figure}

\subsubsection{Numeric Comparison: Linguistic Elements}\label{sec:ling-elements-numeric-comparison}
The distributions of linguistic elements are now compared numerically to each other. To evaluate similarities between the resulting distributions, we apply the \hyperref[sec:wasserstein_distances]{Wasserstein distance} with $p=1$. For each analysis, we compute the Wasserstein distance between the distributions of all pairs of query logs. In Table~\ref{tab:ws-distances-elements} the obtained Wasserstein distances are displayed with regard to the conducted analysis. To assess if the AQL's distributions are similar or rather anomalous, we first calculate the average Wasserstein distance of the comparison group, i.e., AOL, MS-MARCO Web Search and ORCAS. We denote the average Wasserstein distance of the group excluding the AQL by $W_\mu(\overline{AQL})$. Secondly, we determine the average Wasserstein distance between the AQL and the other query logs. For this we consider all possible pairs that contain the AQL and one of the other query logs. We call this average Wasserstein distance $W_\mu(AQL)$. If $W_\mu(AQL) \leq W_\mu(\overline{AQL})$ is true, we can argue that the AQL's distributions are similar enough to be considered a part of the comparison group. If this is not the case, we can conclude that there are significant differences. For a further evaluation, we compute the standard deviation of the Wasserstein distances within the comparison group. We denote the standard deviation of distances within the group excluding the AQL by $\sigma_{\overline{AQL}}$. This allows us to put differences of $W_\mu(AQL)$ and $W_\mu(\overline{AQL})$ into the perspective of average deviations within the comparison group. In all three cases, named entities, words and characters, $W_\mu(AQL)$ is smaller than $W_\mu(\overline{AQL})$. This indicates that the AQL's distributions are similar to the comparison group, suggesting an non-anomalous behaviour of rank-size distributions of linguistic elements when compared to ``true'' query logs.

\begin{table}[tb]
    \centering
    \scalebox{1.0}{
    \begin{tabular}{@{}lrrrr>{\tiny}l>{\small}r@{}} \toprule
        & \multicolumn{4}{c}{\textbf{Named Entities}} & \multicolumn{2}{c}{\textbf{WS-Values}} \\ \cmidrule(l{2pt}r{2pt}){2-5} \cmidrule(l{2pt}r{2pt}){6-7} 
        & AOL & AQL & MS WS & ORCAS & $\mathbf{W_\mu(\overline{AQL})}$ & 272K\\ 
        AOL & - & 91895 & 391408 & 27423 & $\mathbf{W_\mu(AQL)}$ & 163K\\ 
        AQL & 91895 & - & 301466 & 97748 & $\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$ & 108K\\
        MS WS & 391408 & 301466 & - & 397262 & $\mathbf{\sigma_{\overline{AQL}}}$ & 172K\\
        \\[-0.5em]
        ORCAS & 27423 & 97748 & 397262 & - & $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$ & 0.63\\ \midrule
        &  \multicolumn{4}{c}{\textbf{Words}} & \multicolumn{2}{c}{\textbf{WS-Values}}\\ \cmidrule(l{2pt}r{2pt}){2-5} \cmidrule(l{2pt}r{2pt}){6-7}
        & AOL & AQL & MS WS & ORCAS & $\mathbf{W_\mu(\overline{AQL})}$ & 195K\\ 
        AOL & - & 55120 & 216678 & 77063 & $\mathbf{W_\mu(AQL)}$ & 116K\\ 
        AQL & 55120 & - & 161679 & 132184 & $\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$ & 79K\\
        MS WS & 216678 & 161679 & - & 293741 & $\mathbf{\sigma_{\overline{AQL}}}$ & 90K\\
        ORCAS & 77063 & 132184 & 293741 & - & $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$ & 0.89\\ \midrule 
        &  \multicolumn{4}{c}{\textbf{Characters}} & \multicolumn{2}{c}{\textbf{WS-Values}} \\ \cmidrule(l{2pt}r{2pt}){2-5} \cmidrule(l{2pt}r{2pt}){6-7}
        & AOL & AQL & MS WS & ORCAS & $\mathbf{W_\mu(\overline{AQL})}$ & 61\\ 
        AOL & - & 57 & 92 & 1   & $\mathbf{W_\mu(AQL)}$ & 53\\ 
        AQL & 57 & - & 44 & 57   & $\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$ & 8.9\\
        MS WS & 92 & 44 & - & 92   & $\mathbf{\sigma_{\overline{AQL}}}$ & 43\\
        ORCAS & 1 & 57 & 92 & -  & $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$ & 0.21\\ 
        \bottomrule
    \end{tabular}
    }
    \caption{On the left: Wasserstein distances of rank-size distributions of linguistic elements. On the right: various values to evaluate the AQL's similarity to the comparison group, which were motivated in the preceding paragraph (see Section~\ref{sec:ling-elements-numeric-comparison}). The Wasserstein distances are computed with $p=1$.}
    \label{tab:ws-distances-elements}
\end{table}



\subsubsection{Top Queries}
To further evaluate the linguistic elements, we take a look at the top 20 most frequent queries in the query logs. The most frequent queries are listed in Table~\ref{tab:top-queries}. Since MS-MARCO Web Search and ORCAS only contain unique queries, we only have data from the AQL and AOL available to create this table. Moreover, only top queries with latin characters are considered for this table. This is due to the fact that the AQL contains a lot of queries with non-latin characters, e.g., Chinese characters. Since we can not compare these queries with queries from AOL, we replace the six queries of the AQL's top 20 with the next most frequent queries of latin characters. 

It is striking that the top queries of the AOL log are mostly navigational queries, either domain names like ``www.yahoo.com'' or ``www.google.com'' or the mere names of those websites, e.g., ``yahoo'' or ``google''. The AQL's top queries are more diverse and contain a lot of queries that are not navigational. They don't seem very coherent and quite random. A lot of them are even difficult to interpret, such as ``place:86f203b1e5d'', ``\{srch_str\}'' or ``p2045576.m1710''. Some top queries of the AQL even are parts of URLs, e.g., ``http://extras.denverpost.com/media/maps /kml/co...''. In summary, the top queries are substantially different and the AQL's top queries don't seem to reflect realistic user behaviour.   

\subsubsection{Top Words}
Besides the top 20 queries, we additionally take a look at the top 20 most frequent words in the query logs. The most frequent words are listed in Table~\ref{tab:top-words-aol-aql} and Table~\ref{tab:top-words-msmarco-orcas}. To evaluate similarities, we take a look at intersections of the top words. Particularly, we first determine the average intersection of top words within AOL, MS-MARCO Web Search and ORCAS. Considering a collection $G$ of $n$ sets of top words $W_i$, the average cardinality of the pairwise intersections is given by: 
\begin{equation}
    S_\mu(G) = \frac{1}{\binom{n}{2}} \sum_{i=1}^{n} \sum_{j=i+1}^{n} \left| W_i \cap W_j \right|
\end{equation}
We denote the average cardinality of the group excluding the AQL by $S_\mu(\overline{AQL})$. Secondly, we determine the average intersection of top words between the AQL and the other query logs. For this we consider all possible pairs that contain the AQL and one of the other query logs. We call this average cardinality $S_\mu(AQL)$. 
We obtain:
\begin{itemize}
    \item $S_\mu(\overline{AQL}) = 11.66$ 
    \item $S_\mu(AQL) = 9.33$
\end{itemize}
To evaluate how similar the two cardinalities are, we compute the deviation present in the group $\overline{AQL}$ and assess if the deviation of the AQL's average cardinality matches the standard deviation of cardinalities within the comparison group $\overline{AQL}$. For the standard deviation of the group $\overline{AQL}$ we obtain:
\begin{itemize}
    \item $\sigma_{\overline{AQL}} = 1.25$
\end{itemize}
Even though the cardinalities of intersections of top words seem to be in the same range, the deviation of the AQL is slightly higher than the standard deviation in the comparison group. We could conclude that we observe similarites but, despite this, the AQL's top words are still too different to the comparison group to be considered a part of this group. However, the queries of ORCAS and MS-MARCO Web Search are biased to more quetion-like queries, naturally exhibiting higher similarities. Taking this into account, we could also argue that the AQL's top words are not too different from the other query logs. 
\FloatBarrier
\begin{table}[h]
    \centering
    \scalebox{1.0}{
        \begin{tabular}{@{}rlrrlrr@{}} \toprule
        & \multicolumn{3}{c}{\textbf{AOL}}  & \multicolumn{3}{c}{\textbf{AQL}} \\ \cmidrule(l{2pt}r{2pt}){2-4} \cmidrule(l{2pt}r{2pt}){5-7}
        Rank & Word & Count & Ratio & Word & Count & Ratio \\ \midrule
        1 & \texttt{of} & 1,126,030 & 1.26\% & \texttt{=} & 29,301,944 & 1.81\% \\
        2 & \texttt{in} & 946,200 & 1.06\% & \texttt{of} & 12,284,222 & 0.76\% \\
        3 & \texttt{the} & 839,233 & 0.94\% & \texttt{and} & 11,385,504 & 0.71\% \\ 
        4 & \texttt{for} & 698,847 & 0.78\% & \texttt{the} & 8,532,900 & 0.53\% \\ 
        5 & \texttt{and} & 692,798 & 0.78\% & \texttt{site} & 8,466,226 & 0.52\% \\ 
        6 & \texttt{to} & 471,360 & 0.53\% & \texttt{in} & 6,584,034 & 0.41\% \\ 
        7 & \texttt{free} & 450,322 & 0.50\% & \texttt{for} & 6,084,390 & 0.38\% \\ 
        8 & \texttt{a} & 373,919 & 0.42\% & \texttt{-wikipedia} & 5,620,112 & 0.35\% \\ 
        9 & \texttt{google} & 366,059 & 0.41\% & \texttt{to} & 5,588,686 & 0.35\% \\ 
        10 & \texttt{'s} & 359,448 & 0.40\% & \texttt{vector} & 4,544,168 & 0.28\% \\ 
        11 & \texttt{new} & 270,823 & 0.30\% & \texttt{finance} & 4,353,432 & 0.27\% \\ 
        12 & \texttt{http} & 263,056 & 0.29\% & \texttt{\$} & 4,211,514 & 0.26\% \\ 
        13 & \texttt{on} & 254,673 & 0.29\% & \texttt{from} & 4,105,194 & 0.25\% \\ 
        14 & \texttt{pictures} & 236,860 & 0.27\% & \texttt{-site} & 3,983,136 & 0.25\% \\ 
        15 & \texttt{county} & 232,176 & 0.26\% & \texttt{on} & 3,794,202 & 0.24\% \\ 
        16 & \texttt{yahoo} & 219,822 & 0.25\% & \texttt{a} & 3,675,640 & 0.23\% \\ 
        17 & \texttt{how} & 209,175 & 0.23\% & \texttt{kak} & 3,574,962 & 0.22\% \\
        18 & \texttt{lyrics} & 190,043 & 0.21\% & \texttt{2} & 3,554,028 & 0.22\% \\ 
        19 & \texttt{my} & 188,189 & 0.21\% & \texttt{de} & 3,349,984 & 0.21\% \\ 
        20 & \texttt{school} & 183,790 & 0.21\% & \texttt{free} & 3,132,780 & 0.19\% \\ 
        \bottomrule
    \end{tabular}
    }
    \caption{Ranking of the top 20 words in the AOL and AQL. The ratio is computed by dividing the count of a word by the total number of words in the query log.}
    \label{tab:top-words-aol-aql}
\end{table}

\begin{table}[tb]
    \centering
    \scalebox{1.0}{
        \begin{tabular}{@{}rlrrlrr@{}} \toprule
        & \multicolumn{3}{c}{\textbf{MS-MARCO Web Search}}  & \multicolumn{3}{c}{\textbf{ORCAS}} \\ \cmidrule(l{2pt}r{2pt}){2-4} \cmidrule(l{2pt}r{2pt}){5-7}
        Rank & Word & Count & Ratio & Word & Count & Ratio \\ \midrule
        1 & \texttt{the} & 245,317 & 0.83\% & \texttt{of} & 567,790 & 1.65\% \\
        2 & \texttt{de} & 242,823 & 0.82\% & \texttt{to} & 484,322 & 1.41\% \\
        3 & \texttt{in} & 239,674 & 0.81\% & \texttt{in} & 465,981 & 1.36\% \\ 
        4 & \texttt{to} & 214,375 & 0.73\% & \texttt{how} & 393,224 & 1.15\% \\ 
        5 & \texttt{for} & 212,892 & 0.72\% & \texttt{what} & 374,409 & 1.09\% \\ 
        6 & \texttt{} & 212,760 & 0.72\% & \texttt{is} & 367,364 & 1.07\% \\ 
        7 & \texttt{of} & 211,873 & 0.72\% & \texttt{for} & 355,161 & 1.03\% \\ 
        8 & \texttt{a} & 175,659 & 0.59\% & \texttt{the} & 343,583 & 1.00\% \\ 
        9 & \texttt{and} & 127,821 & 0.43\% & \texttt{a} & 268,469 & 0.78\% \\ 
        10 & \texttt{is} & 107,218 & 0.36\% & \texttt{and} & 192,209 & 0.56\% \\ 
        11 & \texttt{how} & 104,567 & 0.35\% & \texttt{on} & 118,872 & 0.35\% \\ 
        12 & \texttt{on} & 68,471 & 0.23\% & \texttt{online} & 117,947 & 0.34\% \\ 
        13 & \texttt{2021} & 67,953 & 0.23\% & \texttt{free} & 106,799 & 0.31\% \\ 
        14 & \texttt{what} & 66,618 & 0.23\% & \texttt{does} & 104,246 & 0.30\% \\ 
        15 & \texttt{download} & 65,442 & 0.22\% & \texttt{definition} & 102,850 & 0.30\% \\ 
        16 & \texttt{sale} & 65,000 & 0.22\% & \texttt{best} & 98,291 & 0.29\% \\ 
        17 & \texttt{online} & 64,211 & 0.22\% & \texttt{do} & 97,787 & 0.28\% \\ 
        18 & \texttt{en} & 62,309 & 0.21\% & \texttt{login} & 94,548 & 0.27\% \\ 
        19 & \texttt{free} & 61,086 & 0.21\% & \texttt{'s} & 93,077 & 0.27\% \\ 
        20 & \texttt{la} & 59,558 & 0.20\% & \texttt{county} & 91,291 & 0.26\% \\ 
        \bottomrule
    \end{tabular}
    }
    \caption{Ranking of the top 20 words in MS-MARCO Web Search and ORCAS. The ratio is computed by dividing the count of a word by the total number of words in the query log.}
    \label{tab:top-words-msmarco-orcas}
\end{table}

\begin{table}[tb]
    \centering
    \scalebox{0.86}{
    \begin{tabular}{@{}rp{0.2\linewidth}rrp{0.29\linewidth}rr@{}} \toprule
        & \multicolumn{3}{c}{\textbf{AOL}}  & \multicolumn{3}{c}{\textbf{AQL}} \\ \cmidrule(l{2pt}r{2pt}){2-4} \cmidrule(l{2pt}r{2pt}){5-7}
        Rank & Query & Count & Ratio & Query & Count & Ratio \\ \midrule
        1 & \texttt{-} & 1,000,375 & 2.75\% & \texttt{finance} & 2,135,183 & 0.78\% \\
        2 & \texttt{google} & 332,192 & 0.92\% & \texttt{\#} & 1,515,866 & 0.55\% \\
        3 & \texttt{ebay} & 139,207 & 0.38\% & \texttt{query} & 1,368,346 & 0.50\% \\ 
        4 & \texttt{yahoo} & 130,538 & 0.35\% & \texttt{\$} & 1,319,815 & 0.49\% \\ 
        5 & \texttt{yahoo.com} & 97,518 & 0.27\% & \texttt{speed force} & 850,884 & 0.31\% \\ 
        6 & \texttt{mapquest} & 88,279 & 0.24\% & \texttt{place:86f203b1e5d c4397} & 414,853 & 0.15\% \\ 
        7 & \texttt{google.com} & 79,991 & 0.22\% & \texttt{``Kurdish Referendum''} &  371,211 & 0.14\% \\ 
        8 & \texttt{myspace.com} & 77,211 & 0.21\% & \texttt{video} & 294,899 & 0.11\% \\ 
        9 & \texttt{myspace} & 74,365 & 0.20\% & \texttt{Latoya Cantrell} & 239,827 & 0.09\% \\ 
        10 & \texttt{myspace.com} & 43,036 & 0.12\% & \texttt{http://extras.denver post.com/media/maps /kml/co...} & 208,918 & 0.08\% \\ 
        11 & \texttt{www.yahoo.com} & 42,597 & 0.12\% & \texttt{\{srch_str\}} & 208,725 & 0.08\% \\ 
        12 & \texttt{www.google.com} & 39,622 & 0.11\% & \texttt{la teachers strike} & 186,735 & 0.07\% \\ 
        13 & \texttt{internet} & 30,125 & 0.08\% & \texttt{rabble.ca} & 157,519 & 0.06\% \\ 
        14 & \texttt{http} & 28,516 & 0.08\% & \texttt{Sarah Stierch} & 146,697 & 0.05\% \\ 
        15 & \texttt{my space} & 27,887 & 0.08\% & \texttt{Aspects} & 143,905 & 0.05\% \\ 
        16 & \texttt{weather} & 27,845 & 0.08\% & \texttt{\#communitywebs} & 139,392 & 0.05\% \\ 
        17 & \texttt{www.myspace.com} & 27,842 & 0.08\% & \texttt{http://dcist.com/ 2015/07/metros_1000-series_ra...} & 130,715 & 0.05\% \\ 
        18 & \texttt{map quest} & 25,856 & 0.08\% & \texttt{prom electric} & 127,972 & 0.05\% \\ 
        19 & \texttt{ebay.com} & 22,893 & 0.07\% & \texttt{p2045576.m1710} & 124,971 & 0.05\% \\ 
        20 & \texttt{american idol} & 22,652 & 0.07\% & \texttt{GFW} & 123,257 & 0.04\% \\ 
        \bottomrule
    \end{tabular}
    }
    \caption{Ranking of the top 20 queries in the respective query logs. Since MS-MARCO and ORCAS only contain unique queries, we only consider AQL and AOL for this table. We also only display queries with latin characters. Because of this, six queries of the AQL's top 20 are replaced with the next most frequent queries of latin characters.}
    \label{tab:top-queries}
\end{table}

\FloatBarrier

\subsection{Length-related Frequencies}
Besides considering the frequency of linguistic elements, we also measure the lengths of the elements in terms of different subcategories. We describe the length of an element by the occuring counts of a possible subcategory, e.g., the length of a query by the count of characters the query contains. From the extraction of named entites and words, we have three sets of categories whose lengths we can measure: queries, named entities and words. To illustrate how we obtain the frequencies of query lengths, named entity lengths and word lengths, we provide a description of how the lengths of queries are measured. Accordingly, we proceed for all categories. The measurement of lengths is carried out in two steps:
\begin{enumerate}
    \item \textbf{Computing Lengths:} We apply the~\verb|map_batches()| API-call to compute the lengths of queries. Since we are interested in the count of named entities, words and characters, we parse a function that performs multiple measurements on each query. We again apply spaCy's \texttt{en\_core\_web\_sm}-model to perform the measurements (e.g., count words or named entities). For each type of measurement (i.e., entity count, word count or character count) the function appends a new column to the batch which contains the corresponding lengths. Eventually, a batch with the computed lengths is returned. 
    \item \textbf{Frequency Measurement:} We apply the~\verb|groupby()| API-call to group the resulting data set by the computed lengths. By this, we obtain a group for each length. Thereon, we call a~\verb|count()| in order to count each length's occurence in the query log. In the end, we obtain a data set with the lengths and their frequencies. 
\end{enumerate}
In Table~\ref{tab:experiment-parameters-lengths}, we again note some key parameters of the experiments that outline the maximum of required ressources and the applied models.
\begin{table}[tb]
    \centering
    \begin{tabular}{@{}lr@{}} \toprule
        \textbf{Max. Number of Workers} & 32 \\    
        \textbf{Max. Number of CPUs per Worker} & 1 \\ 
        \textbf{Max. Memory per Worker} & 9 GB \\ 
        \textbf{Max. Duration} & 22h \\
        \textbf{Used Models} & \textit{spaCy-Tokenizer}, \textit{spaCy-NER} \\
        \bottomrule
    \end{tabular}
    \caption{The parameter values of this table are the extreme values of the configuration to run the frequency measurement of lengths. Both models, the spaCy-Tokenizer and the spaCy-NER are part of the spaCy-model \texttt{en\_core\_web\_sm}\protect\footnotemark, which was used for this analysis.}
    \label{tab:experiment-parameters-lengths}
\end{table}
\footnotetext{{\scriptsize\url{https://github.com/explosion/spacy-models/releases/tag/en_core_web_sm-3.7.1}}}


\subsubsection{Distribution of Character Counts: Queries and Named Entities}
In Figure~\ref{fig:lengths-query-characters-named-entity-characters}, the distributions of query and named entity lengths in characters are displayed. As for queries, the distributions appear to be not very close but still similar to each other. Though, the range of occuring query lengths is quite similar among all logs. Regarding the shape, AOL and AQL are similar, whereas the AQL's distribution is more noisy. ORCAS stands out presenting a binomial-like distribution. MS-MARCO Web Search's distribution is also unique but unlike ORCAS' not symmetrical. Regarding the distributions of named entities, we can again observe a common scope of lengths among all logs and similar shapes. Especially ORCAS and AOL are very similar to one another. The AQL's distribution is similar to a poisson distribution whereas distribution of MS-MARCO Web Search is not exactly assignable to a popular distribution.

\subsubsection{Distributions of Characters per Word and Entities per Queries}
In Figure~\ref{fig:lengths-words-characters-queries-named-entities} the distributions of word and query lengths measured in characters and named entities are displayed. We can observe very similar frequencies of entity counts in queries. The distributions are visually almost equivalent among the involved query logs. As for the word lengths, the distributions are also similar but depict some clear differences, as well. While MS-MARCO Web Search and ORCAS show a very similar distribution, AOL's distribution is clearly different. We can observe an unusual peak of word lengths between 10 and 20 characters. Reviewing AOL's words of this lengths showed that the most frequent words are website addresses in this range. The extensions before and after the website's name (e.g., ``www.'' or ``.com'') cause a shift of frequent words towards longer words. This has been confirmed by filtering out website addresses from the AOL and subsequently measure the word legth distribution. In that case, AOL's distribution of word lengths aligns with the other query logs' distributions. Added to this, the top queries of AOL (see Table~\ref{tab:top-queries}) contain many web sites and domain names, which also confirms the peak in the distribution.

\subsubsection{Distributions of Word Counts: Queries and Named Entities}
In Figure~\ref{fig:lengths-query-words-named-entity-words} the distributions of query and named entity lengths measured in the number of words are displayed. Concerning the lengths of named entities, we can observe almost equivalent distributions of AOL and MS-MARCO Web Search. The distribution of ORCAS is still similar to AOL and MS-MARCO Web Search while the distribution of the AQL is slightly different. The AQL contains significantly more named entities comprised of one word than the other logs. In contrast to the other logs, named entities comprised of one word a the most common named entities. A similarity among all logs is that named entities consisting of two words are the most frequent. As of the query lengths measured in words, we can observe more diverse distributions among the different logs. While the number of words is distributed similarily in AOL and AQL, the distributions of ORCAS and MS-MARCO are different. The distribution of ORCAS resembles a poisson distribution and the distribution of MS-MARCO Web Search is not clearly assignable to a popular distribution. However, the range of the most frequent number of words is similar among all logs.

\subsubsection{Numeric Comparison of Lengths}
The resulting distributions of the measurements are now compared numerically to each other. We again apply the 1-Wasserstein distance to evaluate similarities between the resulting distributions. In Table~\ref{tab:ws-distances-lengths} the obtained Wasserstein distances are displayed with regard to the conducted analysis. The table is structured in a similar way as Table~\ref{tab:ws-distances-lengths}. We again compute the average Wasserstein distance within the comparison group, i.e., AOL, MS-MARCO Web Search and ORCAS, denoted by $W_\mu(\overline{AQL})$. We refer to the standard deviation of wasserstein distances within that group as $\sigma_{\overline{AQL}}$. Additionally, we determine the average Wasserstein distance between the AQL and the other query logs, denoted by $W_\mu(AQL)$. It is striking that we obtain $W_\mu(AQL) > W_\mu(\overline{AQL})$ for all length-related measurements. The closest distribution of the AQL to the comparison group is the distribution of characters per word. In this case, we measure a deviation from the AQL to the comparison group of $0.3~\sigma_{\overline{AQL}}$. The most dissimilar distribution in turn is the query length measured in characters. The deviation of this distribution is $6.1~\sigma_{\overline{AQL}}$. Since we measure substantial deviations of the AQL's distributions we conclude that the AQL is rather anomalous to the comparison group for length-related measurements of linguistic elements. 


\begin{table}[tb]
    \centering
    \scalebox{0.92}{
    \begin{tabular}{l@{\hspace*{0.4em}}r@{\hspace*{0.4em}}r@{\hspace*{0.3em}}r@{\hspace*{0.4em}}r@{\hspace*{0.4em}}r@{\hspace*{0.4em}}r@{\hspace*{0.4em}}r@{\hspace*{0.4em}}r} \toprule
        % &  & Query Length Characters &  &  \\ \midrule
        \multicolumn{5}{c}{\textbf{Characters per Query}} & \multicolumn{4}{c}{\textbf{Characters per Entity}} \\ \cmidrule(l{2pt}r{2pt}){1-5} \cmidrule(l{2pt}r{2pt}){6-9}
        & AOL & AQL & MS WS & ORCAS & AOL & AQL & MS WS & ORCAS \\ 
        AOL & - & 5.54 & 2.56 & 3.72  & - & 2.12 & 1.79 & 0.80 \\ 
        AQL & 5.54 & - & 4.75 & 7.75  & 2.12 & - & 2.86 & 1.98  \\
        MS WS & 2.56 & 4.75 & - & 3.00  & 1.79 & 2.86 & - & 1.03 \\
        ORCAS & 3.72 & 7.75 & 3.00 & - & 0.80 & 1.98 & 1.03 & - \\ \midrule[0.1pt]
        \multicolumn{2}{>{\tiny}l}{$\mathbf{W_\mu(AQL)}$} & 6.0 &  {\tiny$\mathbf{W_\mu(\overline{AQL})}$} & 3.1 & \multicolumn{1}{l}{{\tiny$\mathbf{W_\mu(AQL)}$}} & 2.3 & {\tiny $\mathbf{W_\mu(\overline{AQL})}$} & 1.2 \\
        \multicolumn{2}{>{\tiny}c}{$\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$} & -2.9 &  \multicolumn{1}{l}{{\tiny$\mathbf{\sigma_{\overline{AQL}}}$}} & 0.5 & {\tiny $\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$} & -1.1 & \multicolumn{1}{l}{{\tiny $\mathbf{\sigma_{\overline{AQL}}}$}} & 0.4 \\
        \\[-0.7em]
        \multicolumn{2}{c}{{\tiny $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$}} & -6.1 & & & {\tiny $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$} & -2.6 &&\\ 
        \midrule
        \multicolumn{5}{c}{\textbf{Characters per Word}} & \multicolumn{4}{c}{\textbf{Words per Query}} \\ \cmidrule(l{2pt}r{2pt}){1-5} \cmidrule(l{2pt}r{2pt}){6-9}
        & AOL & AQL & MS WS & ORCAS &  AOL & AQL & MS WS & ORCAS \\ 
        AOL & - & 3.69 & 6.31 & 4.20  & - & 0.58 & 0.69 & 0.89 \\
        AQL & 3.69 & - & 6.29 & 4.17  & 0.58 & - & 0.81 & 1.25  \\
        MS WS & 6.31 & 6.29 & - & 2.20  & 0.69 & 0.81 & - & 0.44 \\
        ORCAS & 4.20 & 4.17 & 2.20 & -  & 0.89 & 1.25 & 0.44 & - \\ \midrule[0.1pt]
        \multicolumn{2}{>{\tiny}l}{$\mathbf{W_\mu(AQL)}$} & 4.7 &  {\tiny$\mathbf{W_\mu(\overline{AQL})}$} & 4.2 & \multicolumn{1}{l}{{\tiny$\mathbf{W_\mu(AQL)}$}} & 0.9 & {\tiny $\mathbf{W_\mu(\overline{AQL})}$} & 0.7 \\
        \multicolumn{2}{>{\tiny}c}{$\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$} & -0.5 &  \multicolumn{1}{l}{{\tiny$\mathbf{\sigma_{\overline{AQL}}}$}} & 1.7 & {\tiny $\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$} & -0.2 & \multicolumn{1}{l}{{\tiny $\mathbf{\sigma_{\overline{AQL}}}$}} & 0.2 \\
        \\[-0.7em]
        \multicolumn{2}{l}{{\tiny $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$}} & -0.3 & & & {\tiny $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$} & -1.1 &&\\ 
        \midrule
        \multicolumn{5}{c}{\textbf{Words per Entity}} & \multicolumn{4}{c}{\textbf{Entities per Query}} \\\cmidrule(l{2pt}r{2pt}){1-5} \cmidrule(l{2pt}r{2pt}){6-9}
        & AOL & AQL & MS WS & ORCAS & AOL & AQL & MS WS & ORCAS \\ 
        AOL & - & 0.19 & 0.06 & 0.11  & - & 0.18 & 0.12 & 0.03 \\
        AQL & 0.19 & - & 0.18 & 0.30  & 0.18 & - & 0.06 & 0.15  \\
        MS WS & 0.06 & 0.18 & - & 0.17  & 0.12 & 0.06 & - & 0.09 \\
        ORCAS & 0.11 & 0.30 & 0.17 & -  & 0.03 & 0.15 & 0.09 & - \\ \midrule[0.1pt]
        \multicolumn{2}{>{\tiny}l}{$\mathbf{W_\mu(AQL)}$} & 0.2 &  {\tiny$\mathbf{W_\mu(\overline{AQL})}$} & 0.1 & \multicolumn{1}{l}{{\tiny$\mathbf{W_\mu(AQL)}$}} & 0.13 & {\tiny $\mathbf{W_\mu(\overline{AQL})}$} & 0.08 \\
        \multicolumn{2}{>{\tiny}c}{$\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$} & -0.1 &  \multicolumn{1}{l}{{\tiny$\mathbf{\sigma_{\overline{AQL}}}$}} & 0.04 & {\tiny $\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$} & -0.05 & \multicolumn{1}{l}{{\tiny $\mathbf{\sigma_{\overline{AQL}}}$}} & 0.04 \\
        \\[-0.7em]
        \multicolumn{2}{c}{{\tiny $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$}} & -2.5 & & & {\tiny $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$} & -1.3 &&\\ 
        \bottomrule
    \end{tabular}
    }
    \caption{Wasserstein distances between the distributions of the query logs. For each analysis, e.g. characters per query, distances of all pairs of query logs are computed. Besides the distances, the table contains values that are relevant for assessing the simlarity of the AQL to the comparison group.}
    \label{tab:ws-distances-lengths}        
\end{table}

\FloatBarrier
\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\textwidth]{../plots/updated_plots/character-count-frequencies-queries-and-character-count-frequencies-named-entities/all.pdf} 
  \caption{The relative frequencies of query and named entity lengths measured in the number of characters are displayed.}
  \label{fig:lengths-query-characters-named-entity-characters}
\end{figure}

\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\textwidth]{../plots/updated_plots/character-count-frequencies-words-and-entity-count-frequencies-queries/all.pdf} 
  \caption{The relative frequencies of word and query lengths are displayed. In this collection, the word length is measured in number of characteres. The query length is measured in the number of occuring named entities.}
  \label{fig:lengths-words-characters-queries-named-entities}
\end{figure}

\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\textwidth]{../plots/updated_plots/word-count-frequencies-queries-and-word-count-frequencies-named-entities/all.pdf} 
  \caption{The relative frequencies of query and named entity lengths are displayed. Both, the query length and the named entity length are measured in number of occuring words.}
  \label{fig:lengths-query-words-named-entity-words}
\end{figure}


\FloatBarrier

\subsection{Search Operators}
As stated in Section~\ref{sec:search_operators}, search operators are a common feature of search engines. They are used to filter the search results or specify specific requirements for the search results. In this section, we analyze the usage of search operators in the query logs. In particular, we determine the ratio of queries, that contain search operators, measure frequencies of the search-operator-count in queries and present the most prominent search operators per query log. The considered search operators of this analysis are:

\begin{multicols}{3}\label{list:search-operators}
    \begin{itemize}
        \item \texttt{AND}
        \item \texttt{OR}
        \item \texttt{around()}
        \item \texttt{site:}
        \item \texttt{filetype:}
        \item \texttt{intitle:}
        \item \texttt{allinurl:}
        \item \texttt{allintitle:}
        \item \texttt{intext:}
        \item \texttt{allintext:}
        \item \texttt{related:}
        \item \texttt{define:}
        \item \texttt{chache:}
    \end{itemize}
\end{multicols}

\subsubsection{Search Operator Frequencies}
First, to obtain the frequencies of the considered search operators in a query log, we apply the~\verb|flat_map()| API-call to extract all search operators from the query log. We parse a function to the API-call that checks for each query if it contains one of the search operators. If so, the search operator is appended to the result set. The function simply checks for the presence of a search operator's string. Thereon, we apply the~\verb|groupby()| API-call to group the data set by the extracted search operators and call a subsequent~\verb|count()| to get the count of each search operator. Similarly we proceed to get the frequencies of search operator counts in queries. We apply the~\verb|map_batches()| API-call to compute the search operator counts of each query. The count is again obtained by a string matching. Then we apply the~\verb|groupby()| API-call to group the data set by the computed search operator counts and call a subsequent~\verb|count()| to get the frequency of each search operator count. 
\subsubsection{Evaluation Search Operators} 
In Table~\ref{tab:search-operators-ratios} the total frequencies of search operators, the search operator ratio and the fraction of queries with different numbers of search operators are displayed. Unfortunately, we couldn't detect any search operators in the AOL log. Since MS-MARCO Web Search and ORCAS only contain unique queries that were filtered by a certain minimum popularity threshold, only very few search operators were detected in these logs. This makes a comparison of the AQL to the other logs difficult and less meaningful. In Table~\ref{tab:search-operators-ranking} a ranking of the considered search operators for each query log is displayed. Again, this comparison lacks meaningfulness since the search operators are not used frequently in the comparison group. Though, the search operator ``site:'' is the most frequent search operator in all query logs. Apart from this commonality, no other meaningful results are visible.

\begin{table}[tb]
    \centering
    \scalebox{0.84}{
    \begin{tabular}{@{}lrrrrrrr@{}} \toprule
        \textbf{Query Log} & \textbf{SO-count} & \textbf{SO-ratio} & $\mathbf{count=0}$ & $\mathbf{count=1}$ & $\mathbf{count=2}$ & $\mathbf{count>2}$ \\ \midrule
        AOL & 0 & 0\% & 100\% & 0\% & 0\% & 0\% \\
        AQL & 7,663,010 & 2.21\% & 97.79\% & 1.83\% & 0.31\% & 0.07\% \\
        MS WS & 6,727 & 0.07\% & 99.93\% & 0.07\% & < 0.00\% & < 0.00\% \\
        ORCAS & 3,937 & 0.04\% & 99.96\% & 0.04\% & < 0.00\% & < 0.00\% \\ \bottomrule
    \end{tabular}
    }
    \caption{Ratios of queries that contain 0, 1, 2, 3, or more than 3 search operators.}
    \label{tab:search-operators-ratios}
\end{table}


\begin{table}[tb]
    \centering
    \scalebox{0.815}{
    \begin{tabular}{@{}rl@{\hspace*{-0.8em}}rrl@{\hspace*{-0.6em}}rrl@{\hspace*{-0.8em}}rr@{}} \toprule
        & \multicolumn{3}{c}{\textbf{AQL}} & \multicolumn{3}{c}{\textbf{MS-MARCO WS}} & \multicolumn{3}{c}{\textbf{ORCAS}} \\ \cmidrule(l{2pt}r{2pt}){2-4} \cmidrule(l{2pt}r{2pt}){5-7} \cmidrule(l{2pt}r{2pt}){8-10} 
        Rank & SO & Count & Ratio & SO & Count & Ratio & SO & Count & Ratio \\ \midrule
        1 & \texttt{site:} & 5,507,994 & 1.59\% & \texttt{site:} & 6,564 & 0.07\% & \texttt{site:} & 3,307 & 0.03\% \\
        2 & \texttt{related:} & 1,471,351 & 0.42\% & \texttt{intitle:} & 80 & 0.00\% & \texttt{define:} & 624 & 0.01\% \\
        3 & \texttt{OR} & 391,561 & 0.11\% & \texttt{define:} & 24 & 0.00\% & \texttt{intitle:} & 4 & 0.00\% \\ 
        4 & \texttt{AND} & 188,382 & 0.05\% & \texttt{intext:} & 22 & 0.00\% & \texttt{related:} & 1 & 0.00\% \\ 
        5 & \texttt{intitle:} & 25,635 & 0.01\% & \texttt{filetype:} & 18 & 0.00\% & \texttt{intext:} & 1 & 0.00\% \\ 
        6 & \texttt{cache:} & 22,566 & 0.01\% & \texttt{cache:} & 12 & 0.00\% & \texttt{allintext:} & 0 & 0.00\% \\ 
        7 & \texttt{define:} & 21,676 & 0.01\% & \texttt{allintext:} & 3 & 0.00\% & \texttt{allinurl:} & 0 & 0.00\% \\ 
        8 & \texttt{allinurl:} & 19,451 & 0.01\% & \texttt{allintitle:} & 3 & 0.00\% & \texttt{allintitle:} & 0 & 0.00\% \\ 
        9 & \texttt{allinurl:} & 5,564 & 0.00\% & \texttt{related:} & 1 & 0.00\% & \texttt{filetype:} & 0 & 0.00\% \\ 
        10 & \texttt{intext:} & 4,950 & 0.00\% & \texttt{AND} & 0 & 0.00\% & \texttt{AND} & 0 & 0.00\% \\ 
        11 & \texttt{allintitle:} & 3,258 & 0.00\% & \texttt{OR} & 0 & 0.00\% & \texttt{OR} & 0 & 0.00\% \\ 
        12 & \texttt{allintext:} & 619 & 0.00\% & \texttt{around():} & 0 & 0.00\% & \texttt{around()} & 0 & 0.00\% \\ 
        12 & \texttt{around()} & 3 & 0.00\% & \texttt{allinurl:} & 0 & 0.00\% & \texttt{chache:} & 0 & 0.00\% \\ 
        \bottomrule
    \end{tabular}
    }
    \caption{Ranking of the used search operators (SO) in the respective query logs. The table does not inlcude data from the AOL log because not a single occurence of the considered search operators was found in it.}
    \label{tab:search-operators-ranking}
\end{table}
% VIELLEICHT NOCH AOL WEGNEHMEN
% \FloatBarrier

\section{Inference-based Statistics}
In this section, we classify queries or components of queries, like named entities, according to selected taxonomies. As described in Section~\ref{sec:query_intent}, the intent behind a query is a meaningful taxonomy according which queries are classified. We also investigate the presence of personally identifiable information (PII) entities in the query logs and their distribution.   

\subsection{Query Intent}
As a first step, we classify queries into the categories informational, navigational and transactional. Since the classifier from \citet{alexander:2022} performs fairly accurate, we apply it in this work. In their work, \citet{alexander:2022} train different models to perform intent classification. We apply the BERT-based model from their collection in this work which achieves an accuracy of $0.90$. Since this classifier of was trained on english queries only, we apply it only to the english subset of the multiligual query logs (AQL and MS-MARCO Web Search). We produce the labels by passing the model to Ray's preferable API-call~\verb|map_batches()| for offline batch inference. After that, we apply the~\verb|groupby()| API-call to group the data set by the labels and get counts for each label. The classifier is not provided publicly, but was obtained by a personal request to \citet{alexander:2022}. In Table~\ref{tab:experiment-parameters-classification} we note some key parameters of the experiments to enhance reproducibility. We only list the parameters' extreme values, indicating the maximum of required ressources.

\subsubsection{Query Intent Distributions}
In Figure~\ref{fig:query-intent} the query intent distributions of the query logs are displayed. The labels were produced by the classifier of \citet{alexander:2022}. The figure shows an equal ranking of the labels. The most frequent label is ``informational'' followed by ``navigational'' and ``transactional''. Apart from the ratio of navigational queries, the distributions are very similar.  
\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\textwidth]{../plots/query-intent/all.pdf} 
  \caption{Distribution of query intents in the query logs. The labels were produced by the classifier of \citet{alexander:2022}. }
  \label{fig:query-intent}
 \end{figure}

\subsection{PII Entity Labels}
Another aspect that we consider is the prevalence of personally identifiable information (PII) in the query logs. We employ Microsoft's Presidio-Model\footnote{\url{https://github.com/microsoft/presidio}} to recognize PII entities in the query logs and store their labels. Microsoft provides an evaluation of the model, demonstrating that it achieves a precision of 0.94 and a recall of 0.55. Again, we produce the labels by applying Ray's preferable API-call~\verb|map_batches()| for offline batch inference. A subsequent \verb|groupby()|-call provides the counts for each label. In Table~\ref{tab:experiment-parameters-classification}, the needed resources and related information to run the classification are listed. 

\begin{table}[tb]
    \centering
    \begin{tabular}{@{}lrr@{}} \toprule
        & \textbf{Intent Labels} & \textbf{PII Labels} \\ \midrule
        \textbf{Max. Number of Workers} & 32 & 320 \\  
        \textbf{Max. Number of CPUs per Worker} & 3 & 1 \\ 
        \textbf{Max. Memory per Worker} & 7 GB & 8GB \\ 
        \textbf{Max. Duration} & 1d 6h & 12h \\
        \textbf{Used Models} & \textit{Intent-Classifier} & \textit{Presidio-Model} \\
        \bottomrule
    \end{tabular}
    \caption{The parameter values of this table indicate the most expensive configuration used to produce intent and PII labels}
    \label{tab:experiment-parameters-classification}
\end{table}

\subsubsection{Label Distributions of PII Entities}
In Figure~\ref{fig:pii-entities} the distributions of PII entities in the query logs is displayed. The labels were produced by Microsoft's Presidio-Model. The figure shows that the same four PII labels are the most frequent ones in all query logs: ``Person'', ``Location'', ``NRP'' (a person's Nationality, religious or political group) and ``Datetime''. Among these four labels however, the distribution varies across the query logs.

\begin{figure}[]
    \centering
    \includegraphics[width=1.0\textwidth]{../plots/group-presidio-pii/all.pdf} 
    \includegraphics[width=1.0\textwidth]{../plots/pii-ratio/all.pdf} 
  \caption{The figure displays the distribution of PII entities in the query logs. The labels were produced by Microsoft's Presidio-Model. The figure shows that the same four PII labels are the most frequent ones in all query logs: ``Person'', ``Location'', ``NRP'' (a person's Nationality, religious or political group) and ``Datetime''. Among these four labels however, the distribution varies across the query logs.}
  \label{fig:pii-entities}
\end{figure}


\subsection{Question Classification}
As a last taxonomy we consider the classification of queries into questions and non-questions. We apply a rule-based classifier provided by \citet{reimer:2023a} to classify queries. The classifier is based on a set of rules that are applied to the queries. The rules are based on the presence of question words (e.g., ``who'', ``what'', ``where'', ``when'', ``how'') or the presence of a question mark at the end of the query. Since the classifier is designed for english queries only, we apply it only to the english subset of the multilingual query logs (AQL and MS-MARCO Web Search). In the study of \citet{reimer:2023a} the classifier achives a recall of $0.89$ and a precision of $0.99$. This classifier as well is not provided publicly, but was obtained by a personal request to \citet{reimer:2023a}. We produce the labels by passing the model to Ray's API-call~\verb|map_batches()| for offline batch inference and apply the~\verb|groupby()| API-call to get the counts for each label. 


\subsubsection{Distributions of Questions}
In Figure~\ref{fig:question-detection} the ratio of questions in each query log is displayed. In general, the ratio of questions is low among all query logs. Not surprisingly, ORCAS contains the most questions as its generation is biased towards questions. The AQL and AOL log contain a similar ratio of questions, while the ratio of questions in the MS-MARCO Web Search log is between ORCAS and the two other logs.
 

\begin{figure}[]
    \centering
    \includegraphics[width=1.0\textwidth]{../plots/questions/all.pdf} 
  \caption{The figure displays the ratio of questions in the query logs. The labels were produced by a rule-based classifier provided by \citet{reimer:2023a}.}
  \label{fig:question-detection}
\end{figure}

\FloatBarrier
\subsection*{Numeric Comparison: Inference-based Distributions}
We compute Wasserstein distances for all pairs of distributions of the different characteristics. Again, we consider the average distance of the AQL to AOL, MS-MARCO Web Search and ORCAS and the average Wasserstein distance within AOL, MS-MARCO Web Search and ORCAS (see Section~\ref{sec:ling-elements-numeric-comparison} for a detailed motivation). Regarding query intent and questions, we note that $W_\mu(AQL) < W_\mu(\overline{AQL})$ which indicates that the AQL is similar to the comparison group. In turn, considering the distribution of PII labels, we note that $W_\mu(AQL) > W_\mu(\overline{AQL})$ which indicates that the AQL is less similar to the comparison group. However, the deviation is equal to $0.75 \sigma_{\overline{AQL}}$ which is not very significant. In summary, we can state that the AQL is reasonably similar for the two insights ``query intent'' and ``questions'' but less similar for the insight ``PII labels''. 
\begin{table}[tb]
    \centering
    \scalebox{1.0}{
    \begin{tabular}{@{}lrrrr>{\tiny}l>{\small}r@{}} \toprule
        & \multicolumn{4}{c}{\textbf{Query Intent}} & \multicolumn{2}{c}{\textbf{WS-Values}} \\ \cmidrule(l{2pt}r{2pt}){2-5} \cmidrule(l{2pt}r{2pt}){6-7} 
        & AOL & AQL & MS WS & ORCAS & $\mathbf{W_\mu(\overline{AQL})}$ & 0.18\\ 
        AOL & - & 0.17 & 0.26 & 0.20 & $\mathbf{W_\mu(AQL)}$ & 0.10\\ 
        AQL & 0.17 & - & 0.10 & 0.04 & $\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$ & 0.08\\
        MS WS & 0.26 & 0.10 & - & 0.07 & $\mathbf{\sigma_{\overline{AQL}}}$ & 0.08\\
        \\[-0.5em]
        ORCAS & 0.20 & 0.04 & 0.07 & - & $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$ & 1.00\\ \midrule
        &  \multicolumn{4}{c}{\textbf{PII Labels}} & \multicolumn{2}{c}{\textbf{WS-Values}}\\ \cmidrule(l{2pt}r{2pt}){2-5} \cmidrule(l{2pt}r{2pt}){6-7}
        & AOL & AQL & MS WS & ORCAS & $\mathbf{W_\mu(\overline{AQL})}$ & 0.16\\ 
        AOL & - & 0.22 & 0.17 & 0.09 & $\mathbf{W_\mu(AQL)}$ & 0.21\\ 
        AQL & 0.22 & - & 0.17 & 0.22 & $\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$ & -0.04\\
        MS WS & 0.17 & 0.17 & - & 0.23 & $\mathbf{\sigma_{\overline{AQL}}}$ & 0.06\\
        ORCAS & 0.09 & 0.22 & 0.23 & - & $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$ & -0.75\\ \midrule 
        &  \multicolumn{4}{c}{\textbf{Questions}} & \multicolumn{2}{c}{\textbf{WS-Values}} \\ \cmidrule(l{2pt}r{2pt}){2-5} \cmidrule(l{2pt}r{2pt}){6-7}
        & AOL & AQL & MS WS & ORCAS & $\mathbf{W_\mu(\overline{AQL})}$ & 0.05\\ 
        AOL & - & 0.5e-2 & 2.9e-2 & 7.5e-2   & $\mathbf{W_\mu(AQL)}$ & 0.03\\ 
        AQL & 0.5e-2 & - & 2.4e-2 & 6.9e-2   & $\mathbf{W_\mu(\overline{AQL}) - W_\mu(AQL)}$ & 0.02\\
        MS WS & 2.9e-2 & 2.4e-2 & - & 4.6e-2   & $\mathbf{\sigma_{\overline{AQL}}}$ & 0.02\\
        ORCAS & 7.5e-2 & 6.9e-2 & 4.6e-2 & -  & $\mathbf{\frac{W_\mu(\overline{AQL}) - W_\mu(AQL)}{\sigma_{\overline{AQL}}}}$ & 0.90\\ 
        \bottomrule
    \end{tabular}
    }
    \caption{On the left: Wasserstein distances of inference-based distributions. On the right: various values to evaluate the AQL's similarity to the comparison group, which were motivated in Section~\ref{sec:ling-elements-numeric-comparison}. The Wasserstein distances are computed with $p=1$.}
    \label{tab:ws-distances-inference}
\end{table}


\subsection{Case Study: Probabilistic Approach}
So far we have calculated mean and standard deviation of Wasserstein distances to assess whether the AQL is similar or anomalous to the comparison group of AOL, MS-MARCO Web Search and ORCAS. Following this logic, one could estimate a probability distribution from the Wasserstein distances and use it to model the ``true'' distribution for a considered characteristic. From the pairwise calculation of Wasserstein distances, we obtain a distance matrix $D \in \mathbb{R}^{4\times4}$. Since the Wasserstein distance is a metric, a configuration of the distributions in three dimensions is naturally induced. We denote the space of this embedding the Wasserstein space $\mathcal{W}$. Provided that $\mathcal{W}$ is a Euclidean space in our use cases, mean and standard deviation can be calculated straightforward. Given that the ground truth $W$ is normally distributed in the Wasserstein space, 
\[
  W \sim \mathcal{N}(\mu,\,\sigma^{2})
\]  
one could predict the probability of a distribution belonging to the ground truth by the distance to the mean of the ground truth. An estimation of the ground truth mean and standard deviation is obtained by the mean $W_\mu(\overline{AQL})$ and standard deviation $\sigma_{\overline{AQL}}$ of distances within the comparison group. According to this, the probability of a new sample belonging to ground truth can be estimated by its deviation from the ground truth mean. For simplification, we express the deviation of the AQL from the mean of the comparison group $W_\mu(\overline{AQL})$ in the number of sigma deviations $\sigma_{\overline{AQL}}$ which is also called z-score. The probabilities of samples with a certain z-score are straightforward:
\begin{align*}
    P(|X-\mu| \geq \sigma) &= 0.32 \\
    P(|X-\mu| \geq 2\sigma) &= 0.04 \\
    P(|X-\mu| \geq 3\sigma) &= 0.003 \\
\end{align*}From Table~\ref{tab:ws-distances-elements}, Table~\ref{tab:ws-distances-lengths} and Table~\ref{tab:ws-distances-inference} we can now obtain the calculated z-scores for the AQL. For simplification we round the z-scores to integers. For a z-score of 0 we assign a probability of 100\% and a z-score that is higher than 4 we assign 0\%. The resulting probabilites are displayed in Table~\ref{tab:ws-distances-z-scores}. Averaging these probabilites would give us a probability of 58.66\% that the AQL belongs to the comparison group. However, this approach is simplified and requires the satisfaction of many assumptions. In Figure~\ref{fig:ws-distances-comb} and~\ref{fig:ws-distances-elements} a visualization of the probabilistic approach is displayed. The original configuration in 3D was embedded into 2D by applying multidimensional scaling (MDS)~\citep{kruskal:1964}.
\begin{table}[h]
    \centering
    \begin{tabular}{@{}lrrrr@{}} \toprule
        \textbf{Lengths} & 100\% & 100\% & 100\%  \\ 
        \textbf{Elements} & 0\% & 4\% & 100\%  \\
        \textbf{Elements} & 32\% & 4\% & 32\%  \\
        \textbf{Inference-based} & 100\% & 32\% & 100\% \\ 
        \bottomrule
    \end{tabular}
    \caption{Z-scores of the AQL to the comparison group of AOL, MS-MARCO Web Search and ORCAS for the different characteristics of the query logs}
    \label{tab:ws-distances-z-scores}
\end{table}  
\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\textwidth]{../plots/Wasserstein-Distances-elements-2d-contour/all.pdf} 
  \caption{Wasserstein distances of rank-size distributions of linguistic elements. The distance matrix induces a configuration of the four distributions in $\mathbb{R}^3$. By applying multidimensional scaling (MDS)~\citep{kruskal:1964}, we obtain the visualized embedding in $\mathbb{R}^2$. The white area corresponds to a point's average distance $d_{\mu}$ to the comparison group that satisfies $d_{\mu} < W_\mu(\overline{AQL})$. A point's location in one of the colored areas satisfies $W_\mu(\overline{AQL}) + n \cdot \sigma_{\overline{AQL}} \leq d_{\mu} \leq W_\mu(\overline{AQL}) + (n+1) \cdot \sigma_{\overline{AQL}}$ for $n \in \mathbb{N}_0$.}
  \label{fig:ws-distances-elements}
\end{figure}


\begin{figure}[tb]
    \begin{center}
        
    \includegraphics[width=0.98\textwidth]{../plots/Wasserstein-Distances-inference-2d-contour-no-legend/all.pdf} 
    % \vspace{1cm}
    \includegraphics[width=1.0\textwidth]{../plots/Wasserstein-Distances-lengths-2d-contour/all.pdf} 
  \caption{Wasserstein distances of distributions of lengths. The distance matrix induces a configuration of the four distributions in $\mathbb{R}^3$. By applying multidimensional scaling (MDS)~\citep{kruskal:1964}, we obtain the visualized embedding in $\mathbb{R}^2$. The white area corresponds to a point's average distance $d_{\mu}$ to the comparison group that satisfies $d_{\mu} < W_\mu(\overline{AQL})$. A point's location in one of the colored areas satisfies $W_\mu(\overline{AQL}) + n \cdot \sigma_{\overline{AQL}} \leq d_{\mu} \leq W_\mu(\overline{AQL}) + (n+1) \cdot \sigma_{\overline{AQL}}$ for $n \in \mathbb{N}_0$.}
  \label{fig:ws-distances-comb}
    \end{center}
\end{figure}




\FloatBarrier

\section{Temporal-based Analysis}
In this section, we aim at performing temporal-based comparisons of real-world queries and queries of the AQL. To realize this, we select a set of Google queries which we download from the tool ``Google Trends''. We select two sets, one with annual top queries and one with monthly top queries. As for the annual top queries, we simply compare the top queries of Google Trends with the AQL's top queries. For the monthly top queries, we compare temporal patterns of real-world queries and queries of the AQL. We expect monthly top queries to be more volatile that annual top queries which is why we prefer them for a comparison of temporal patterns. We carry out this comparison by computing the temporal correlation of the queries's popularity.

\subsubsection*{Google Trends}
Before conducting the temporal comparison, we must select a set of queries that we want to utilize for the comparison. In order to meet the constraints of Google Trends (see Section~\ref{sec:google_trends}), we select queries that are popular. Moreover, we consider a sufficiently long time span for the comparison. Google Trends offers to download the top 25 popular queries from a selected time span. We use this option to create two sets of queries for our comparison. 
First, we consider the annual top queries of Google and secondly the monthly top queries of Google. For the annual top queries we perform a simple comparison to the AQL's annual top queries. For the monthly top queries, we compute temporal correlations between the AQL and Google Trends. 

\subsection{Annual Top Queries}
First, we consider annual top queries of Google and use them for comparisons. We create a list of the annual top 25 from 2004 until 2022. 2004 is the earliest year for which Google Trends provides data and 2022 is the latest year for which the AQL contains queries. Similarly, we create a list of the annual top 25 queries from the AQL for the same time span. For this, we first filter the AQL for queries that stem from Google and afterwards create the annual top 25. As a first comparison, we simply determine the intersection of the two lists with respect to the year. That is, for each year we check if the top 25 queries of Google Trends are also present in the AQL's top 25 queries. We can observe that the intersection is quite small. In fact, only 7 queries out of possible 475 queries are present in both respective top 25 annual queries. The queries are \texttt{facebook} (2 times), \texttt{google} (2 times), \texttt{youtube} (2 times) and \texttt{yahoo}. This indicates that the distribution of Google queries in the AQL is not very similar to the real distribution of Google queries.        


\subsection{Temporal Correlation}
Secondly, we consider monthly top queries of Google. For this analysis we attempt to assess the similarity of temporal patterns between queries from Google and the AQL. We choose monthly top queries because we expect monthly top queries to be more volatile than annual top queries. Since there are lots of duplicates in the monthly top queries, we need to create a ranking of the monthly top queries. By this, we can compare the most popular queries of the monthly top queries. To do this, we first create a list of the monthly top 25 queries from Google from 2004 until 2022. For each month, we obtain a list of the top 25 queries. We then create a ranking of theses queries by employing reciprocal rank fusion~\citep{cormack:2009}. Reciprocal rank fusion is a method to combine multiple ranked lists into a single ranking. Given a set $I$ of items to be ranked and a set $R$ of rankings, the RRF-Score is computed by
\begin{equation}
    RRF(i \in I) = \sum_{r \in R} \frac{1}{k + r(i)}
\end{equation}   
where $k$ is a constant (usually set to 60) and $r(i)$ is the rank of item $i$ in ranking $r$. The method assigns a score to each item in the list based on its positions in the original lists. The score is calculated as the reciprocal of the rank, so that higher-ranked items receive higher scores. The final score for each item is then computed by summing the scores from all lists. We feed all monthly top 25 Google queries from 2004 until 2022 into the RRF-Score function to obtain a final ranking of the top 25 monthly queries. From this, we obtain the following ranking: 

\begin{multicols}{4}\label{list:top-25-monthly-google-queries}
    \begin{enumerate}
        \item \texttt{google}
        \item \texttt{yahoo}
        \item \texttt{weather}
        \item \texttt{youtube}
        \item \texttt{hotmail}
        \item \texttt{facebook}
        \item \texttt{gmail}
        \item \texttt{news}
        \item \texttt{you}
        \item \texttt{ebay}
        \item \texttt{amazon}   
        \item \texttt{games}
        \item \texttt{free}
        \item \texttt{twitter}
        \item \texttt{translate}
        \item \texttt{mp3}
        \item \texttt{maps}
        \item \texttt{msn}
        \item \texttt{fb}
        \item \texttt{mail}
        \item \texttt{instagram}
        \item \texttt{map}
        \item \texttt{face}
        \item \texttt{video}
        \item \texttt{juegos}
    \end{enumerate}
\end{multicols}
\subsubsection{Measuring Query Frequencies in the AQL}
We then search these queries in the AQL and measure their frequency over time. We achieve this by applying the~\verb|map_batches()| API-call to first filter the AQL's queries for the considered top queries and secondly to map the timestamps of the queries into the format \verb|(YYYY-MM)|. Then, we apply the~\verb|groupby()| API-call to group by queries and timestamp. Thereon, we call a~\verb|count()| to get the count of each query per month. The result is a data set with the counts of each query per month. In case a query is not present in the AQL during a specific month between 2004 and 2022, we set the count to 0. Eventually, we get a list of queries with their counts per month. In order to obtain the popularity of a query in a specific month, we divide the counts of each query by the sum of all counts of the present Google queries in the AQL in that month. This gives us a relative frequency of each query in that month which represents its popularity. Since the data of Google trends is projected to the scale [0,100], we also scale the relative frequencies of the AQL to the interval [0,100]. After this, we can proceed to compute the temporal correlation of the queries between the AQL and Google Trends.
\subsubsection{Computing Temporal Correlations} 
To assess the similarity of the temporal patterns, we compute the temporal correlation of the queries between the AQL and Google Trends. Given two queries $q$ and $p$, their respective frequency functions $X_{i,q}$ and $X_{i,p}$ with $d$ time steps, their mean $\mu_{q}$ and $\mu_{p}$ and their standard deviation $\sigma_{q}$ and $\sigma_{p}$, then, according to \citet{chien:2005}, their temporal correlation is computed by:
\begin{equation}
    \rho_{q,p} = \frac{1}{d} \sum_i \left( \frac{X_{i,q} - \mu_{q}}{\sigma_{q}} \right) \cdot \left( \frac{X_{i,p} - \mu_{p}}{\sigma_{p}} \right)
\end{equation} 
The correlation coefficient $\rho_{q,p}$ indicates the strength and direction of the linear relationship between the two queries' frequency functions. The value of $\rho_{q,p}$ ranges from -1 to 1, where -1 indicates a perfect negative correlation, 0 indicates no correlation and 1 indicates a perfect positive correlation. Since the time spans are aligned, we are looking only for positive correlations as an indicator of similarity. We compute the temporal correlation for each query in the AQL with respect to its counterpart in Google Trends. In Table~\ref{tab:temporal-correlation} we display the resultig correlation coefficients. The table shows that most queries have a positive correlation with their counterpart in Google Trends, but the correlation coefficients are mostly very low. In addition, there are also some queries with a negative correlation. To get a visual impression of the similarity, we plot the two time series that refelct the highest correlation. 
% In Figure~\ref{fig:temporal-correlation} we show the time series of the query \texttt{translate}. As we can see, the popularity within the AQL is much more volatile than the popularity of the query in Google Trends. Considering the overall low correlations of the 25 queries and the fact that this is the query with the highest correlation, we can conclude that the temporal popularity of queries in the AQL is substantially different from the temporal popularity of queries in Google Trends.


\begin{table}[tb]
    \centering
    \begin{tabular}{@{}rlrrlrrlr@{}} \toprule
        \textbf{\#} & \textbf{Query} & $\mathbf{\rho_{q,p}}$ & \textbf{\#} & \textbf{Query} & $\mathbf{\rho_{q,p}}$ & \textbf{\#} & \textbf{Query} & $\mathbf{\rho_{q,p}}$ \\ \cmidrule(l{2pt}r{2pt}){1-3} \cmidrule(l{2pt}r{2pt}){4-6} \cmidrule(l{2pt}r{2pt}){7-9} 
        1&\texttt{google} & 0.22 & 2&\texttt{yahoo} & 0.16 & 3&\texttt{weather} & 0.24 \\  
        4&\texttt{youtube} & 0.17 & 5&\texttt{hotmail} & 0.01 & 6&\texttt{facebook} & 0.04 \\
        7&\texttt{gmail} & -0.02 & 8&\texttt{news} & 0.01 & 9&\texttt{you} & 0.09 \\
        10&\texttt{ebay} & 0.07 & 11&\texttt{amazon} & 0.20 & 12&\texttt{games} & -0.04 \\
        13&\texttt{free} & -0.11 & 14&\texttt{twitter} & 0.27 & 15&\texttt{translate} & 0.40 \\
        16&\texttt{mp3} & -0.01 & 17&\texttt{maps} & 0.06 & 18&\texttt{msn} & 0.11 \\
        19&\texttt{fb} & 0.17 & 20&\texttt{mail} & 0.19 & 21&\texttt{instagram} & 0.28 \\
        22&\texttt{map} & -0.06 & 23&\texttt{face} & 0.25 & 24&\texttt{video} & 0.01 \\
        25&\texttt{juegos} & 0.09 &  &  &  &  \\ 
        \bottomrule
    \end{tabular}
    \caption{The table displays the resulting correlation coefficients of the temporal popularity. For a given query $q$ in the AQL, the correlation coefficient $\rho_{q,p}$ is computed with respect to its counterpart $p$ in Google Trends. The table shows that most queries have a positive correlation with their counterpart in Google Trends, but the correlation coefficients are mostly very low. In addition, there are also some queries with a negative correlation, indicating that the temporal popularity of queries is substantially different between the AQL and Google Trends.}
    \label{tab:temporal-correlation}
\end{table}

\begin{figure}[tb]
    \centering
    \includegraphics[width=1.0\textwidth]{../plots/time-series-google-trends/all.pdf} 
  \caption{The figure shows temporal popularity of the queries ``translate'', ``instagram'', ``twitter'' and ``face'' in the AQL and Google. We consider these 4 queries because they have the highest correlation coefficients, showcasing that even the highest correlated time series are quite different.}
  \label{fig:time-series}
 \end{figure}
    
% \FloatBarrier


% To be positioned


% \section{Embedding-based Analysis}




% {'google': 0.21904851193584732, 'yahoo': 0.15904812650944658, 'weather': 0.23624534461790192, 'youtube': 0.17030650778343326, 'hotmail': 0.006745560399899185, 'facebook': 0.044298329003901335, 'gmail': -0.016379371677375545, 'news': 0.014114180639545795, 'you': 0.08693177691315236, 'ebay': 0.06776898206041422, 'amazon': 0.20019592168041728, 'games': -0.03879771049665855, 'free': -0.10915038913864314, 'twitter': 0.2735821131175976, 'translate': 0.3991971403856061, 'mp3': -0.009645428425897553, 'maps': 0.06408956789931061, 'msn': 0.10896897607438608, 'fb': 0.17292276415645547, 'mail': 0.18771473115814052, 'instagram': 0.28032287589686367, 'map': -0.05665690356281852, 'face': 0.24679975747851507, 'video': 0.006289646087909414, 'juegos': 0.08609699769876895}









