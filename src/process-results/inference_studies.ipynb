{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d72b1db",
   "metadata": {},
   "source": [
    "# Study of the resulting distributions\n",
    "In this notebook we want to compare the resulting distributions by applying the wasserstein distance to quantify differences and similarities.\n",
    "## Frequencies of Linguistic Elements\n",
    "To assess the similarity of the resulting distributions, we compute the [*Wasserstein-Metric*](https://en.wikipedia.org/wiki/Wasserstein_metric) of each pair of distributions.\n",
    "The Wasserstein-Metric is a distance function for probability distributions. It satisfies the criteria of actual metrics and thus enables comparisons between probability distributions. Assuming one-dimensional distributions, the Wasserstein Distance of two empirical samples $P$ and $Q$ with respective random vectors $X_1,...,X_n$ and $Y_1,...,Y_n$ is given by:\n",
    "\n",
    "$W_{p}(P,Q)=\\left({\\frac{1}{n}}\\sum_{i=1}^{n}\\|X_{(i)}-Y_{(i)}\\|^{p}\\right)^{\\frac{1}{p}}$ \n",
    "\n",
    "Let's compute the Wasserstein-Metric for the distributions of query intent, PII Entity Labels and Questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e47fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis_schneg.vis_modules import _get_results_paths, load_results\n",
    "\n",
    "analyses = []\n",
    "\n",
    "analyses.append('query-intent')\n",
    "analyses.append('group-presidio-pii')\n",
    "analyses.append('questions')\n",
    "\n",
    "# test_data = True\n",
    "test_data = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf4e5f",
   "metadata": {},
   "source": [
    "Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "# load data\n",
    "\n",
    "analysis_data = {}\n",
    "for analysis in analyses:\n",
    "    # col_name = 'query-intent'\n",
    "    # title = 'Query Intent'\n",
    "    if analysis == 'group-presidio-pii':\n",
    "        cleaned_aql = True\n",
    "        # col_name = 'entity-label'\n",
    "        # title = 'PII Entity Labels'\n",
    "    else:\n",
    "        cleaned_aql = False\n",
    "\n",
    "    if analysis == 'questions':\n",
    "        english = True\n",
    "        # col_name = 'is-question'\n",
    "        # title = 'Questions'\n",
    "    else:\n",
    "        english = False\n",
    "    print(f\"Start loading \\\"{analysis}\\\"\")\n",
    "    datasets = {}\n",
    "    for dataset in [\"aol\",\"aql\",\"ms-marco\",\"orcas\"]:\n",
    "        start_time = time()\n",
    "        paths = _get_results_paths(dataset, analysis, cleaned_aql=cleaned_aql, english=english)\n",
    "        result_data = load_results(paths, test_data=test_data)\n",
    "        datasets.update({dataset: result_data})\n",
    "        end_time = time()\n",
    "        print(f\"{dataset.upper()} loaded in {(end_time - start_time)/60} min\")\n",
    "    analysis_data.update({analysis: datasets})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca865aff",
   "metadata": {},
   "source": [
    "Compute Wasserstein-Distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "cnt=0\n",
    "distances_data = {}\n",
    "\n",
    "for analysis, datasets in analysis_data.items():\n",
    "\n",
    "    col_name = 'query-intent'\n",
    "    if analysis == 'group-presidio-pii':\n",
    "        col_name = 'entity-label'\n",
    "        # title = 'PII Entity Labels'\n",
    "    if analysis == 'questions':\n",
    "        col_name = 'is-question'\n",
    "        # title = 'Questions'\n",
    "\n",
    "    distances = DataFrame(np.zeros((len(datasets), len(datasets))), index=datasets.keys(), columns=datasets.keys())\n",
    "    names = []\n",
    "    j=0\n",
    "    for dataset_name, data in datasets.items():\n",
    "        names.append(dataset_name)\n",
    "        data = data.sort_values(by=[col_name], ascending=False)\n",
    "        # remove the columns that contain less than 0.4% of the total count\n",
    "        data = data[data['count()'] > 0.004 * data['count()'].sum()]\n",
    "        y_vals = (data['count()']/data['count()'].sum()).to_numpy()\n",
    "        print(f\"{dataset_name}: {y_vals}\")\n",
    "        i=0\n",
    "        for dataset_name, data in datasets.items():\n",
    "            if dataset_name in names:\n",
    "                dist = 0\n",
    "            else:\n",
    "                data = data.sort_values(by=[col_name], ascending=False)\n",
    "                data = data[data['count()'] > 0.004 * data['count()'].sum()]\n",
    "\n",
    "                y_vals2 = (data['count()']/data['count()'].sum()).to_numpy()\n",
    "                # in this cas,e the wasserstein distance corresponds to the differences of the counts in the categories multiplied by 1/2\n",
    "                # we postulate a distance of 1 between the categories: dist(informational, navigational) = 1\n",
    "                dist = 0.5 * np.sum(np.abs(y_vals - y_vals2)) \n",
    "\n",
    "            distances.iloc[i, j] = dist\n",
    "            i+=1\n",
    "        j+=1\n",
    "    distances = distances + distances.T\n",
    "    distances_data.update({analysis: distances})\n",
    "    cnt+=1\n",
    "for key, value in distances_data.items():\n",
    "    print(value)\n",
    "\n",
    "\n",
    "## get avarage wasserstein distances per query log\n",
    "avg_distances = {}\n",
    "for analysis, distances in distances_data.items():\n",
    "    avg_distances.update({analysis: distances.mean().mean()})\n",
    "    \n",
    "for key, value in avg_distances.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b1ba9",
   "metadata": {},
   "source": [
    "Let's get some insights into the results of the WS distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ws_stats(distancedata):\n",
    "    ws_stats = {}\n",
    "    for analysis, distances in distancedata.items():\n",
    "        # get distances of AOL, MS MARCO, ORCAS\n",
    "        aol = distances.loc['aol'].to_numpy()\n",
    "        # print(aol)\n",
    "        ms_marco = distances.loc['ms-marco'].to_numpy()\n",
    "        orcas = distances.loc['orcas'].to_numpy()\n",
    "        # get distances of AQL\n",
    "        aql = distances.loc['aql'].to_numpy()\n",
    "        # print(aol,aql,ms_marco,orcas,sep='\\n')\n",
    "        aql_dist = aql.sum()/3\n",
    "        notaql_dist = (aol[2]+aol[3]+ms_marco[3])/3\n",
    "        std = np.std([aol[2], aol[3], ms_marco[3]])\n",
    "        aql_dist_deviation = aql_dist - notaql_dist\n",
    "        aql_distinSTD = aql_dist_deviation/std\n",
    "        ws_stats.update({analysis: [aql_dist, notaql_dist, aql_dist_deviation, std, aql_distinSTD]})\n",
    "    return ws_stats\n",
    "        \n",
    "for key, value in get_ws_stats(distances_data).items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c82a4",
   "metadata": {},
   "source": [
    "By applying MDS, we project the configuration into 2D and create another plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import MDS\n",
    "# mds = MDS(n_components=2, dissimilarity='precomputed')\n",
    "\n",
    "# distances = distances_data[analysis]\n",
    "\n",
    "# print(distances)\n",
    "# points =  mds.fit_transform(distances)\n",
    "# print(points)\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed')\n",
    "trans_dists = {}\n",
    "for key, value in distances_data.items():\n",
    "    print(key)\n",
    "    trans_dists.update({key: mds.fit_transform(value)})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd330d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path  \n",
    "from sklearn.manifold import MDS\n",
    "import scienceplots\n",
    "\n",
    " # now we create a colormap, that reflects the average distance of a point to the 3 points of AOL, ORCAS, MS-MARCO Web Search\n",
    "# index 1 in the points array is the point of AQL\n",
    "def avg_dist_notAQL(x,y, point_matrtix):\n",
    "    dist = 0\n",
    "    for i in range(len(point_matrtix)):\n",
    "        if i != 1:\n",
    "            dist += np.sqrt((x - point_matrtix[i][0])**2 + (y - point_matrtix[i][1])**2)\n",
    "    dist = dist/3\n",
    "    # return dist\n",
    "    # # get the average distance of the points within AOL, ORCAS, MS-MARCO Web Search    \n",
    "    avg_dist_within = 0\n",
    "    for i in [(0,2), (0,3), (2,3)]:\n",
    "        avg_dist_within += np.sqrt((point_matrtix[i[0]][0] - point_matrtix[i[1]][0])**2 + (point_matrtix[i[0]][1] - point_matrtix[i[1]][1])**2)\n",
    "    avg_dist_within = avg_dist_within/3\n",
    "\n",
    "    # get the standard deviation of distances within AOL, ORCAS, MS-MARCO Web Search\n",
    "    std_dist_within = 0\n",
    "    for i in [(0,2), (0,3), (2,3)]:\n",
    "        std_dist_within += (np.sqrt((point_matrtix[i[0]][0] - point_matrtix[i[1]][0])**2 + (point_matrtix[i[0]][1] - point_matrtix[i[1]][1])**2) - avg_dist_within)**2\n",
    "    std_dist_within = np.sqrt(std_dist_within/3) \n",
    "\n",
    "    if dist <= avg_dist_within:\n",
    "        return avg_dist_within\n",
    "    elif dist > avg_dist_within and dist <= avg_dist_within + std_dist_within:\n",
    "        return avg_dist_within + std_dist_within\n",
    "    elif dist > avg_dist_within + std_dist_within and dist <= avg_dist_within + 2 * std_dist_within:\n",
    "        return avg_dist_within + 2 * std_dist_within\n",
    "    elif dist > avg_dist_within + 2 * std_dist_within and dist <= avg_dist_within + 3 * std_dist_within:\n",
    "        return avg_dist_within + 3 * std_dist_within\n",
    "    elif dist > avg_dist_within + 3 * std_dist_within and dist <= avg_dist_within + 4 * std_dist_within:\n",
    "        return avg_dist_within + 4 * std_dist_within\n",
    "        \n",
    "def avg_dist_within(points):\n",
    "    dist = 0\n",
    "    pairs = [(0, 2), (0, 3), (2, 3)]  # Indizes der Punkte AOL, MS-MARCO, ORCAS\n",
    "    for i, j in pairs:\n",
    "        dist += np.sqrt((points[i][0] - points[j][0])**2 + (points[i][1] - points[j][1])**2)\n",
    "    return dist / len(pairs)\n",
    "def std_within(points):\n",
    "    dist = 0\n",
    "    pairs = [(0, 2), (0, 3), (2, 3)]  # Indizes der Punkte AOL, MS-MARCO, ORCAS\n",
    "    for i, j in pairs:\n",
    "        dist += (np.sqrt((points[i][0] - points[j][0])**2 + (points[i][1] - points[j][1])**2) - avg_dist_within(points))**2\n",
    "    return np.sqrt(dist / len(pairs))\n",
    "\n",
    "# use science style for plots from scienceplots library\n",
    "plt.style.use([\"science\", \"ieee\"])\n",
    "\n",
    "color =  ['tab:blue', 'tab:orange', 'tab:gray', 'tab:red']\n",
    "\n",
    "save_vis = True\n",
    "# save_vis = False\n",
    "# plot_legend = True\n",
    "plot_legend = False\n",
    "\n",
    "# get meshsize\n",
    "# mesh_size = 70\n",
    "mesh_size = 500\n",
    "\n",
    "num_plots = 3\n",
    "cols = 3\n",
    "rows = num_plots//cols\n",
    "if num_plots % cols != 0:\n",
    "    rows+=1\n",
    "\n",
    "textwidth = 5.5129\n",
    "aspect_ratio = 6/8\n",
    "scale = 1.0\n",
    "width = textwidth * scale *1.1\n",
    "height = width * aspect_ratio * 0.45\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(rows,cols, figsize=(width,height))\n",
    "\n",
    "titles = [\"Query Intent\", \"PII Entities\", \"Questions\"]\n",
    "print(titles)\n",
    "\n",
    "positions = [[0.0,0.0], [0.0,-0.6], [-0.02,0.0]]\n",
    "keys = [key for key in trans_dists.keys()]\n",
    "\n",
    "axes = ax.flatten()\n",
    "for i in range(len(trans_dists)):\n",
    "    ax = axes[i]\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "    points = trans_dists[keys[i]]\n",
    "    # get the highes and lowest x and y values of the points\n",
    "    x_min = np.min(points[:,0])\n",
    "    x_max = np.max(points[:,0])\n",
    "    y_min = np.min(points[:,1])\n",
    "    y_max = np.max(points[:,1])\n",
    "\n",
    "    # scale the extreme values of x and y to get a good boundary for the plot\n",
    "    # we take the scale of the min range\n",
    "    range_scale = 0.4\n",
    "    x_min = x_min - range_scale * (x_max - x_min)\n",
    "    x_max = x_max + range_scale * (x_max - x_min)\n",
    "    y_min = y_min - range_scale * (y_max - y_min)\n",
    "    y_max = y_max + range_scale * (y_max - y_min)\n",
    "\n",
    "    x = np.linspace(x_min, x_max, mesh_size)\n",
    "    y = np.linspace(y_min, y_max, mesh_size)\n",
    "    z = np.array([avg_dist_notAQL(i,j,points) for j in y for i in x])\n",
    "\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = z.reshape(mesh_size, mesh_size)\n",
    "\n",
    "    avg_dist = avg_dist_within(points)\n",
    "    std_dist = std_within(points)\n",
    "\n",
    "    ax.contourf(X.astype(float), Y.astype(float), Z.astype(float), 10, alpha=0.7, cmap = 'Blues', linewidths=0.5, linestyles='solid') #, cmap='Blues' 'OrRd'\n",
    "    # Add contour lines for the average distance within AOL, MS-MARCO, and ORCAS and the standard deviation \n",
    "    contour = ax.contour(X, Y, Z, levels=[avg_dist, avg_dist+std_dist, avg_dist+2*std_dist, avg_dist+3*std_dist], colors='black', linewidths=0.5, linestyles='dashed')\n",
    "\n",
    "    # Label the contour lines with descriptive text\n",
    "    # text = [\"$d_{{\\mu}}$\", \"$d_{{\\mu}} + \\sigma$\", \"$d_{{\\mu}} + 2 \\sigma$\"]\n",
    "    text = [\"$d_{{\\mu}}$\",\"\",\"\"]\n",
    "\n",
    "    for i, level in enumerate(contour.levels):\n",
    "        # Find the position for the label (e.g., the midpoint of the contour line)\n",
    "        idx = np.where(Z == level)\n",
    "        if len(idx[0]) > 0:\n",
    "            if i > 0 and i < 2:\n",
    "                # Find the position where y is closest to 0\n",
    "                y_closest_to_zero_idx = np.argmin(np.abs(Y[idx]))\n",
    "                x_pos = X[idx][y_closest_to_zero_idx] +0.006\n",
    "                y_pos = Y[idx][y_closest_to_zero_idx] -0.015\n",
    "                ax.text(x_pos, y_pos, text[i] , fontsize=10, color='black')\n",
    "            elif i == 0:\n",
    "                x_pos = X[idx[0][0], idx[1][0]] - 0.005# Shift slightly in the x-direction\n",
    "                y_pos = Y[idx[0][0], idx[1][0]] + 0.05\n",
    "                ax.text(x_pos, y_pos, text[i] , fontsize=10, color='black')\n",
    "\n",
    "    labels = [name.upper() for name in names]\n",
    "    labels[2] = \"MS-MARCO WS\"\n",
    "    # plot 3d scatter plot\n",
    "    for j in range(len(points)):\n",
    "        ax.scatter(points[j][0], points[j][1], c=color[j], label=labels[j], s=30, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "    ax.grid(True)\n",
    "\n",
    "if plot_legend:\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.01), fancybox=False, ncol=len(names),edgecolor=\"black\", frameon=True).get_frame().set_linewidth(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "base_path = \"/home/benjamin/studium/masterarbeit/thesis-schneg/plots/\"\n",
    "if plot_legend:\n",
    "    vis_dir = Path(f\"{base_path}Wasserstein-Distances-inference-2d-contour\")\n",
    "else:\n",
    "    vis_dir = Path(f\"{base_path}Wasserstein-Distances-inference-2d-contour-no-legend\")\n",
    "\n",
    "if not vis_dir.exists() and save_vis:\n",
    "        vis_dir.mkdir(parents=True)\n",
    "\n",
    "if not vis_dir.exists() and save_vis:\n",
    "        vis_dir.mkdir(parents=True)\n",
    "\n",
    "if save_vis:\n",
    "    fig.savefig(vis_dir.joinpath(\"all.pdf\"), format='pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
